{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4850640f-ec60-495c-b839-0dde8a1e255a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jXObXC-DaHqo"
   },
   "outputs": [],
   "source": [
    "def data_preparation(data):\n",
    "    df = pd.read_csv(data)\n",
    "    df = df.sample(n= 6000, random_state=1)\n",
    "    y = df.pop('power')\n",
    "    y = y.values\n",
    "    y = y.reshape(-1,1)\n",
    "    X = df.values\n",
    "    X = df\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kV_gxJ5vpnjY"
   },
   "outputs": [],
   "source": [
    "seed = 23\n",
    "X, y = data_preparation('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "c7Gosab0ofwV"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state= seed)\n",
    "\n",
    "scaler1 = MinMaxScaler()\n",
    "X_train = scaler1.fit_transform(X_train)\n",
    "X_val = scaler1.transform(X_val)\n",
    "X_test = scaler1.transform(X_test)\n",
    "\n",
    "scaler2 = MinMaxScaler()\n",
    "y_train = scaler2.fit_transform(y_train)\n",
    "y_val = scaler2.transform(y_val)\n",
    "y_test = scaler2.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PXp4QBqX4BL7"
   },
   "outputs": [],
   "source": [
    "#X_small_shift, y_small_shift = data_preparation('dev_in.csv')\n",
    "X_shift, y_shift = data_preparation('dev_out.csv')\n",
    "\n",
    "X_shift = scaler1.transform(X_shift)\n",
    "y_shift = scaler2.transform(y_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZVjy_y7_KiXJ"
   },
   "outputs": [],
   "source": [
    "# Generate OOD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_iJeMbRnKiXJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/xue_long_tf/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Sonar.csv\n",
    "OOD = pd.read_csv('Boston_Housing_test.csv')\n",
    "OOD = OOD.iloc[:, 1:12]\n",
    "OOD = OOD.values\n",
    "OOD = scaler1.transform(OOD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3QVoGRayWYqM"
   },
   "outputs": [],
   "source": [
    "# pip install -U -q --use-deprecated=legacy-resolver tf-models-official tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "f71bf3b4-f060-443e-a3a1-b60a042d6643"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 22:32:04.683453: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-12 22:32:04.699027: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-12 22:32:04.699041: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-12 22:32:04.699482: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-12 22:32:04.702404: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-12 22:32:05.090140: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "import tensorflow as tf\n",
    "tf.autograph.set_verbosity(0)\n",
    "import official.nlp.modeling.layers as nlp_layers\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sChybeczlG7F"
   },
   "outputs": [],
   "source": [
    "class DeepResNet(tf.keras.Model):\n",
    "  \"\"\"Defines a multi-layer residual network.\"\"\"\n",
    "  def __init__(self, num_classes, num_layers= 3, num_hidden=128,\n",
    "               dropout_rate=0.1, **classifier_kwargs):\n",
    "    super().__init__()\n",
    "    # Defines class meta data.\n",
    "    self.num_hidden = num_hidden\n",
    "    self.num_layers = num_layers\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.classifier_kwargs = classifier_kwargs\n",
    "\n",
    "    # Defines the hidden layers.\n",
    "    self.input_layer = tf.keras.layers.Dense(self.num_hidden, trainable=False)\n",
    "    self.dense_layers = [self.make_dense_layer() for _ in range(num_layers)]\n",
    "\n",
    "    # Defines the output layer.\n",
    "    self.classifier = self.make_output_layer(num_classes)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Projects the 2d input data to high dimension.\n",
    "    hidden = self.input_layer(inputs)\n",
    "\n",
    "    # Computes the ResNet hidden representations.\n",
    "    for i in range(self.num_layers):\n",
    "      resid = self.dense_layers[i](hidden)\n",
    "      resid = tf.keras.layers.Dropout(self.dropout_rate)(resid)\n",
    "      hidden += resid\n",
    "\n",
    "    return hidden, self.classifier(hidden)\n",
    "\n",
    "  def make_dense_layer(self):\n",
    "    \"\"\"Uses the Dense layer as the hidden layer.\"\"\"\n",
    "    return tf.keras.layers.Dense(self.num_hidden, activation=\"relu\")\n",
    "\n",
    "  def make_output_layer(self, num_classes):\n",
    "    \"\"\"Uses the Dense layer as the output layer.\"\"\"\n",
    "    return tf.keras.layers.Dense(\n",
    "        num_classes, **self.classifier_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fLp49uvslG9n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deep_res_net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  1536      \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  16512     \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  16512     \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51201 (200.00 KB)\n",
      "Trainable params: 49665 (194.00 KB)\n",
      "Non-trainable params: 1536 (6.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 22:32:05.439560: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-12 22:32:05.457347: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-12 22:32:05.457459: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-12 22:32:05.458644: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-12 22:32:05.458737: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-12 22:32:05.458784: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-12 22:32:05.533412: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-12 22:32:05.533501: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-12 22:32:05.533552: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-12 22:32:05.533594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 870 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "resnet_config = dict(num_classes = 1, num_layers= 3, num_hidden= 128) # （2 64  0.007） （2 32 0.006）\n",
    "resnet_model = DeepResNet(**resnet_config)\n",
    "resnet_model.build( (None, 11) )\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zjqvk2fUlHFr"
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "metrics = tf.keras.metrics.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate= 1e-4)\n",
    "\n",
    "train_config = dict(loss=loss, metrics=metrics, optimizer=optimizer)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 100,\n",
    "                                            restore_best_weights = True)\n",
    "\n",
    "fit_config = dict( batch_size= 64,  epochs= 1000,\n",
    "                validation_data = (X_val, y_val),\n",
    "                callbacks=[callback] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lEgDNUB7KDxc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "68/68 [==============================] - 1s 3ms/step - loss: 0.4013 - output_1_loss: 0.2218 - output_2_loss: 0.1796 - output_1_mean_squared_error: 0.2218 - output_2_mean_squared_error: 0.1796 - val_loss: 0.2251 - val_output_1_loss: 0.1963 - val_output_2_loss: 0.0288 - val_output_1_mean_squared_error: 0.1963 - val_output_2_mean_squared_error: 0.0288\n",
      "Epoch 2/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.2353 - output_1_loss: 0.1927 - output_2_loss: 0.0426 - output_1_mean_squared_error: 0.1927 - output_2_mean_squared_error: 0.0426 - val_loss: 0.1693 - val_output_1_loss: 0.1592 - val_output_2_loss: 0.0101 - val_output_1_mean_squared_error: 0.1592 - val_output_2_mean_squared_error: 0.0101\n",
      "Epoch 3/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.1858 - output_1_loss: 0.1558 - output_2_loss: 0.0300 - output_1_mean_squared_error: 0.1558 - output_2_mean_squared_error: 0.0300 - val_loss: 0.1306 - val_output_1_loss: 0.1231 - val_output_2_loss: 0.0075 - val_output_1_mean_squared_error: 0.1231 - val_output_2_mean_squared_error: 0.0075\n",
      "Epoch 4/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.1573 - output_1_loss: 0.1283 - output_2_loss: 0.0290 - output_1_mean_squared_error: 0.1283 - output_2_mean_squared_error: 0.0290 - val_loss: 0.1045 - val_output_1_loss: 0.0987 - val_output_2_loss: 0.0058 - val_output_1_mean_squared_error: 0.0987 - val_output_2_mean_squared_error: 0.0058\n",
      "Epoch 5/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.1364 - output_1_loss: 0.1095 - output_2_loss: 0.0270 - output_1_mean_squared_error: 0.1095 - output_2_mean_squared_error: 0.0270 - val_loss: 0.0879 - val_output_1_loss: 0.0829 - val_output_2_loss: 0.0050 - val_output_1_mean_squared_error: 0.0829 - val_output_2_mean_squared_error: 0.0050\n",
      "Epoch 6/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1244 - output_1_loss: 0.0992 - output_2_loss: 0.0251 - output_1_mean_squared_error: 0.0992 - output_2_mean_squared_error: 0.0251 - val_loss: 0.0796 - val_output_1_loss: 0.0750 - val_output_2_loss: 0.0047 - val_output_1_mean_squared_error: 0.0750 - val_output_2_mean_squared_error: 0.0047\n",
      "Epoch 7/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.1171 - output_1_loss: 0.0934 - output_2_loss: 0.0237 - output_1_mean_squared_error: 0.0934 - output_2_mean_squared_error: 0.0237 - val_loss: 0.0731 - val_output_1_loss: 0.0681 - val_output_2_loss: 0.0049 - val_output_1_mean_squared_error: 0.0681 - val_output_2_mean_squared_error: 0.0049\n",
      "Epoch 8/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1104 - output_1_loss: 0.0875 - output_2_loss: 0.0229 - output_1_mean_squared_error: 0.0875 - output_2_mean_squared_error: 0.0229 - val_loss: 0.0675 - val_output_1_loss: 0.0633 - val_output_2_loss: 0.0042 - val_output_1_mean_squared_error: 0.0633 - val_output_2_mean_squared_error: 0.0042\n",
      "Epoch 9/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.1051 - output_1_loss: 0.0833 - output_2_loss: 0.0218 - output_1_mean_squared_error: 0.0833 - output_2_mean_squared_error: 0.0218 - val_loss: 0.0634 - val_output_1_loss: 0.0588 - val_output_2_loss: 0.0046 - val_output_1_mean_squared_error: 0.0588 - val_output_2_mean_squared_error: 0.0046\n",
      "Epoch 10/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.1006 - output_1_loss: 0.0798 - output_2_loss: 0.0208 - output_1_mean_squared_error: 0.0798 - output_2_mean_squared_error: 0.0208 - val_loss: 0.0593 - val_output_1_loss: 0.0554 - val_output_2_loss: 0.0039 - val_output_1_mean_squared_error: 0.0554 - val_output_2_mean_squared_error: 0.0039\n",
      "Epoch 11/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0960 - output_1_loss: 0.0761 - output_2_loss: 0.0199 - output_1_mean_squared_error: 0.0761 - output_2_mean_squared_error: 0.0199 - val_loss: 0.0557 - val_output_1_loss: 0.0519 - val_output_2_loss: 0.0038 - val_output_1_mean_squared_error: 0.0519 - val_output_2_mean_squared_error: 0.0038\n",
      "Epoch 12/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0922 - output_1_loss: 0.0733 - output_2_loss: 0.0189 - output_1_mean_squared_error: 0.0733 - output_2_mean_squared_error: 0.0189 - val_loss: 0.0527 - val_output_1_loss: 0.0490 - val_output_2_loss: 0.0037 - val_output_1_mean_squared_error: 0.0490 - val_output_2_mean_squared_error: 0.0037\n",
      "Epoch 13/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0893 - output_1_loss: 0.0710 - output_2_loss: 0.0183 - output_1_mean_squared_error: 0.0710 - output_2_mean_squared_error: 0.0183 - val_loss: 0.0497 - val_output_1_loss: 0.0461 - val_output_2_loss: 0.0036 - val_output_1_mean_squared_error: 0.0461 - val_output_2_mean_squared_error: 0.0036\n",
      "Epoch 14/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0862 - output_1_loss: 0.0683 - output_2_loss: 0.0180 - output_1_mean_squared_error: 0.0683 - output_2_mean_squared_error: 0.0180 - val_loss: 0.0473 - val_output_1_loss: 0.0431 - val_output_2_loss: 0.0042 - val_output_1_mean_squared_error: 0.0431 - val_output_2_mean_squared_error: 0.0042\n",
      "Epoch 15/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0833 - output_1_loss: 0.0653 - output_2_loss: 0.0180 - output_1_mean_squared_error: 0.0653 - output_2_mean_squared_error: 0.0180 - val_loss: 0.0442 - val_output_1_loss: 0.0406 - val_output_2_loss: 0.0036 - val_output_1_mean_squared_error: 0.0406 - val_output_2_mean_squared_error: 0.0036\n",
      "Epoch 16/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0804 - output_1_loss: 0.0628 - output_2_loss: 0.0176 - output_1_mean_squared_error: 0.0628 - output_2_mean_squared_error: 0.0176 - val_loss: 0.0411 - val_output_1_loss: 0.0380 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0380 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 17/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0776 - output_1_loss: 0.0609 - output_2_loss: 0.0167 - output_1_mean_squared_error: 0.0609 - output_2_mean_squared_error: 0.0167 - val_loss: 0.0386 - val_output_1_loss: 0.0355 - val_output_2_loss: 0.0030 - val_output_1_mean_squared_error: 0.0355 - val_output_2_mean_squared_error: 0.0030\n",
      "Epoch 18/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0753 - output_1_loss: 0.0589 - output_2_loss: 0.0164 - output_1_mean_squared_error: 0.0589 - output_2_mean_squared_error: 0.0164 - val_loss: 0.0379 - val_output_1_loss: 0.0340 - val_output_2_loss: 0.0038 - val_output_1_mean_squared_error: 0.0340 - val_output_2_mean_squared_error: 0.0038\n",
      "Epoch 19/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0721 - output_1_loss: 0.0569 - output_2_loss: 0.0151 - output_1_mean_squared_error: 0.0569 - output_2_mean_squared_error: 0.0151 - val_loss: 0.0362 - val_output_1_loss: 0.0316 - val_output_2_loss: 0.0046 - val_output_1_mean_squared_error: 0.0316 - val_output_2_mean_squared_error: 0.0046\n",
      "Epoch 20/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0703 - output_1_loss: 0.0552 - output_2_loss: 0.0152 - output_1_mean_squared_error: 0.0552 - output_2_mean_squared_error: 0.0152 - val_loss: 0.0328 - val_output_1_loss: 0.0299 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0299 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 21/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0684 - output_1_loss: 0.0534 - output_2_loss: 0.0150 - output_1_mean_squared_error: 0.0534 - output_2_mean_squared_error: 0.0150 - val_loss: 0.0314 - val_output_1_loss: 0.0284 - val_output_2_loss: 0.0030 - val_output_1_mean_squared_error: 0.0284 - val_output_2_mean_squared_error: 0.0030\n",
      "Epoch 22/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0667 - output_1_loss: 0.0521 - output_2_loss: 0.0146 - output_1_mean_squared_error: 0.0521 - output_2_mean_squared_error: 0.0146 - val_loss: 0.0307 - val_output_1_loss: 0.0273 - val_output_2_loss: 0.0034 - val_output_1_mean_squared_error: 0.0273 - val_output_2_mean_squared_error: 0.0034\n",
      "Epoch 23/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0650 - output_1_loss: 0.0510 - output_2_loss: 0.0140 - output_1_mean_squared_error: 0.0510 - output_2_mean_squared_error: 0.0140 - val_loss: 0.0285 - val_output_1_loss: 0.0259 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0259 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 24/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0634 - output_1_loss: 0.0498 - output_2_loss: 0.0136 - output_1_mean_squared_error: 0.0498 - output_2_mean_squared_error: 0.0136 - val_loss: 0.0275 - val_output_1_loss: 0.0245 - val_output_2_loss: 0.0030 - val_output_1_mean_squared_error: 0.0245 - val_output_2_mean_squared_error: 0.0030\n",
      "Epoch 25/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0629 - output_1_loss: 0.0488 - output_2_loss: 0.0141 - output_1_mean_squared_error: 0.0488 - output_2_mean_squared_error: 0.0141 - val_loss: 0.0265 - val_output_1_loss: 0.0239 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0239 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 26/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0606 - output_1_loss: 0.0478 - output_2_loss: 0.0128 - output_1_mean_squared_error: 0.0478 - output_2_mean_squared_error: 0.0128 - val_loss: 0.0254 - val_output_1_loss: 0.0227 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0227 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 27/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0598 - output_1_loss: 0.0468 - output_2_loss: 0.0130 - output_1_mean_squared_error: 0.0468 - output_2_mean_squared_error: 0.0130 - val_loss: 0.0238 - val_output_1_loss: 0.0212 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0212 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 28/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0589 - output_1_loss: 0.0460 - output_2_loss: 0.0129 - output_1_mean_squared_error: 0.0460 - output_2_mean_squared_error: 0.0129 - val_loss: 0.0233 - val_output_1_loss: 0.0208 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0208 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 29/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0571 - output_1_loss: 0.0453 - output_2_loss: 0.0119 - output_1_mean_squared_error: 0.0453 - output_2_mean_squared_error: 0.0119 - val_loss: 0.0225 - val_output_1_loss: 0.0200 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0200 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 30/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0563 - output_1_loss: 0.0445 - output_2_loss: 0.0119 - output_1_mean_squared_error: 0.0445 - output_2_mean_squared_error: 0.0119 - val_loss: 0.0213 - val_output_1_loss: 0.0187 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0187 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 31/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0558 - output_1_loss: 0.0438 - output_2_loss: 0.0120 - output_1_mean_squared_error: 0.0438 - output_2_mean_squared_error: 0.0120 - val_loss: 0.0206 - val_output_1_loss: 0.0182 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0182 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 32/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0547 - output_1_loss: 0.0430 - output_2_loss: 0.0117 - output_1_mean_squared_error: 0.0430 - output_2_mean_squared_error: 0.0117 - val_loss: 0.0204 - val_output_1_loss: 0.0179 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0179 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 33/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0537 - output_1_loss: 0.0425 - output_2_loss: 0.0112 - output_1_mean_squared_error: 0.0425 - output_2_mean_squared_error: 0.0112 - val_loss: 0.0195 - val_output_1_loss: 0.0170 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0170 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 34/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0533 - output_1_loss: 0.0419 - output_2_loss: 0.0114 - output_1_mean_squared_error: 0.0419 - output_2_mean_squared_error: 0.0114 - val_loss: 0.0191 - val_output_1_loss: 0.0168 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0168 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 35/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0525 - output_1_loss: 0.0413 - output_2_loss: 0.0112 - output_1_mean_squared_error: 0.0413 - output_2_mean_squared_error: 0.0112 - val_loss: 0.0184 - val_output_1_loss: 0.0159 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0159 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 36/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0513 - output_1_loss: 0.0408 - output_2_loss: 0.0106 - output_1_mean_squared_error: 0.0408 - output_2_mean_squared_error: 0.0106 - val_loss: 0.0194 - val_output_1_loss: 0.0157 - val_output_2_loss: 0.0037 - val_output_1_mean_squared_error: 0.0157 - val_output_2_mean_squared_error: 0.0037\n",
      "Epoch 37/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0509 - output_1_loss: 0.0403 - output_2_loss: 0.0106 - output_1_mean_squared_error: 0.0403 - output_2_mean_squared_error: 0.0106 - val_loss: 0.0172 - val_output_1_loss: 0.0148 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0148 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 38/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0509 - output_1_loss: 0.0400 - output_2_loss: 0.0108 - output_1_mean_squared_error: 0.0400 - output_2_mean_squared_error: 0.0108 - val_loss: 0.0169 - val_output_1_loss: 0.0145 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0145 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 39/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0498 - output_1_loss: 0.0397 - output_2_loss: 0.0101 - output_1_mean_squared_error: 0.0397 - output_2_mean_squared_error: 0.0101 - val_loss: 0.0164 - val_output_1_loss: 0.0141 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0141 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 40/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0491 - output_1_loss: 0.0391 - output_2_loss: 0.0100 - output_1_mean_squared_error: 0.0391 - output_2_mean_squared_error: 0.0100 - val_loss: 0.0169 - val_output_1_loss: 0.0141 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0141 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 41/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0484 - output_1_loss: 0.0389 - output_2_loss: 0.0095 - output_1_mean_squared_error: 0.0389 - output_2_mean_squared_error: 0.0095 - val_loss: 0.0163 - val_output_1_loss: 0.0136 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0136 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 42/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0476 - output_1_loss: 0.0379 - output_2_loss: 0.0097 - output_1_mean_squared_error: 0.0379 - output_2_mean_squared_error: 0.0097 - val_loss: 0.0149 - val_output_1_loss: 0.0126 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0126 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 43/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0470 - output_1_loss: 0.0372 - output_2_loss: 0.0097 - output_1_mean_squared_error: 0.0372 - output_2_mean_squared_error: 0.0097 - val_loss: 0.0163 - val_output_1_loss: 0.0126 - val_output_2_loss: 0.0036 - val_output_1_mean_squared_error: 0.0126 - val_output_2_mean_squared_error: 0.0036\n",
      "Epoch 44/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0462 - output_1_loss: 0.0370 - output_2_loss: 0.0092 - output_1_mean_squared_error: 0.0370 - output_2_mean_squared_error: 0.0092 - val_loss: 0.0146 - val_output_1_loss: 0.0123 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0123 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 45/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0457 - output_1_loss: 0.0367 - output_2_loss: 0.0090 - output_1_mean_squared_error: 0.0367 - output_2_mean_squared_error: 0.0090 - val_loss: 0.0145 - val_output_1_loss: 0.0120 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0120 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 46/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0460 - output_1_loss: 0.0365 - output_2_loss: 0.0095 - output_1_mean_squared_error: 0.0365 - output_2_mean_squared_error: 0.0095 - val_loss: 0.0160 - val_output_1_loss: 0.0124 - val_output_2_loss: 0.0036 - val_output_1_mean_squared_error: 0.0124 - val_output_2_mean_squared_error: 0.0036\n",
      "Epoch 47/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0451 - output_1_loss: 0.0362 - output_2_loss: 0.0090 - output_1_mean_squared_error: 0.0362 - output_2_mean_squared_error: 0.0090 - val_loss: 0.0134 - val_output_1_loss: 0.0114 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0114 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 48/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0454 - output_1_loss: 0.0360 - output_2_loss: 0.0094 - output_1_mean_squared_error: 0.0360 - output_2_mean_squared_error: 0.0094 - val_loss: 0.0139 - val_output_1_loss: 0.0115 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0115 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 49/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0448 - output_1_loss: 0.0357 - output_2_loss: 0.0091 - output_1_mean_squared_error: 0.0357 - output_2_mean_squared_error: 0.0091 - val_loss: 0.0143 - val_output_1_loss: 0.0117 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0117 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 50/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0439 - output_1_loss: 0.0356 - output_2_loss: 0.0084 - output_1_mean_squared_error: 0.0356 - output_2_mean_squared_error: 0.0084 - val_loss: 0.0137 - val_output_1_loss: 0.0110 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0110 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 51/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0442 - output_1_loss: 0.0354 - output_2_loss: 0.0088 - output_1_mean_squared_error: 0.0354 - output_2_mean_squared_error: 0.0088 - val_loss: 0.0141 - val_output_1_loss: 0.0112 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0112 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 52/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0435 - output_1_loss: 0.0350 - output_2_loss: 0.0084 - output_1_mean_squared_error: 0.0350 - output_2_mean_squared_error: 0.0084 - val_loss: 0.0134 - val_output_1_loss: 0.0107 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0107 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 53/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0432 - output_1_loss: 0.0348 - output_2_loss: 0.0083 - output_1_mean_squared_error: 0.0348 - output_2_mean_squared_error: 0.0083 - val_loss: 0.0142 - val_output_1_loss: 0.0106 - val_output_2_loss: 0.0036 - val_output_1_mean_squared_error: 0.0106 - val_output_2_mean_squared_error: 0.0036\n",
      "Epoch 54/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0428 - output_1_loss: 0.0344 - output_2_loss: 0.0084 - output_1_mean_squared_error: 0.0344 - output_2_mean_squared_error: 0.0084 - val_loss: 0.0126 - val_output_1_loss: 0.0104 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0104 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 55/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0424 - output_1_loss: 0.0342 - output_2_loss: 0.0081 - output_1_mean_squared_error: 0.0342 - output_2_mean_squared_error: 0.0081 - val_loss: 0.0123 - val_output_1_loss: 0.0101 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0101 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 56/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0417 - output_1_loss: 0.0339 - output_2_loss: 0.0078 - output_1_mean_squared_error: 0.0339 - output_2_mean_squared_error: 0.0078 - val_loss: 0.0139 - val_output_1_loss: 0.0102 - val_output_2_loss: 0.0037 - val_output_1_mean_squared_error: 0.0102 - val_output_2_mean_squared_error: 0.0037\n",
      "Epoch 57/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0423 - output_1_loss: 0.0339 - output_2_loss: 0.0084 - output_1_mean_squared_error: 0.0339 - output_2_mean_squared_error: 0.0084 - val_loss: 0.0121 - val_output_1_loss: 0.0097 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0097 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 58/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0413 - output_1_loss: 0.0335 - output_2_loss: 0.0078 - output_1_mean_squared_error: 0.0335 - output_2_mean_squared_error: 0.0078 - val_loss: 0.0115 - val_output_1_loss: 0.0093 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0093 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 59/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0406 - output_1_loss: 0.0331 - output_2_loss: 0.0075 - output_1_mean_squared_error: 0.0331 - output_2_mean_squared_error: 0.0075 - val_loss: 0.0129 - val_output_1_loss: 0.0094 - val_output_2_loss: 0.0034 - val_output_1_mean_squared_error: 0.0094 - val_output_2_mean_squared_error: 0.0034\n",
      "Epoch 60/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0409 - output_1_loss: 0.0330 - output_2_loss: 0.0079 - output_1_mean_squared_error: 0.0330 - output_2_mean_squared_error: 0.0079 - val_loss: 0.0122 - val_output_1_loss: 0.0093 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0093 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 61/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0405 - output_1_loss: 0.0330 - output_2_loss: 0.0075 - output_1_mean_squared_error: 0.0330 - output_2_mean_squared_error: 0.0075 - val_loss: 0.0129 - val_output_1_loss: 0.0097 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0097 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 62/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0402 - output_1_loss: 0.0326 - output_2_loss: 0.0076 - output_1_mean_squared_error: 0.0326 - output_2_mean_squared_error: 0.0076 - val_loss: 0.0112 - val_output_1_loss: 0.0091 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0091 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 63/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0400 - output_1_loss: 0.0326 - output_2_loss: 0.0074 - output_1_mean_squared_error: 0.0326 - output_2_mean_squared_error: 0.0074 - val_loss: 0.0112 - val_output_1_loss: 0.0092 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0092 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 64/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0392 - output_1_loss: 0.0323 - output_2_loss: 0.0069 - output_1_mean_squared_error: 0.0323 - output_2_mean_squared_error: 0.0069 - val_loss: 0.0109 - val_output_1_loss: 0.0087 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0087 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 65/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0395 - output_1_loss: 0.0321 - output_2_loss: 0.0074 - output_1_mean_squared_error: 0.0321 - output_2_mean_squared_error: 0.0074 - val_loss: 0.0108 - val_output_1_loss: 0.0085 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0085 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 66/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0389 - output_1_loss: 0.0316 - output_2_loss: 0.0073 - output_1_mean_squared_error: 0.0316 - output_2_mean_squared_error: 0.0073 - val_loss: 0.0111 - val_output_1_loss: 0.0084 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0084 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 67/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0388 - output_1_loss: 0.0319 - output_2_loss: 0.0070 - output_1_mean_squared_error: 0.0319 - output_2_mean_squared_error: 0.0070 - val_loss: 0.0125 - val_output_1_loss: 0.0090 - val_output_2_loss: 0.0035 - val_output_1_mean_squared_error: 0.0090 - val_output_2_mean_squared_error: 0.0035\n",
      "Epoch 68/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0384 - output_1_loss: 0.0314 - output_2_loss: 0.0069 - output_1_mean_squared_error: 0.0314 - output_2_mean_squared_error: 0.0069 - val_loss: 0.0113 - val_output_1_loss: 0.0084 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0084 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 69/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0385 - output_1_loss: 0.0316 - output_2_loss: 0.0069 - output_1_mean_squared_error: 0.0316 - output_2_mean_squared_error: 0.0069 - val_loss: 0.0105 - val_output_1_loss: 0.0084 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0084 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 70/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0382 - output_1_loss: 0.0316 - output_2_loss: 0.0067 - output_1_mean_squared_error: 0.0316 - output_2_mean_squared_error: 0.0067 - val_loss: 0.0105 - val_output_1_loss: 0.0084 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0084 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 71/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0381 - output_1_loss: 0.0313 - output_2_loss: 0.0068 - output_1_mean_squared_error: 0.0313 - output_2_mean_squared_error: 0.0068 - val_loss: 0.0108 - val_output_1_loss: 0.0082 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0082 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 72/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0377 - output_1_loss: 0.0311 - output_2_loss: 0.0066 - output_1_mean_squared_error: 0.0311 - output_2_mean_squared_error: 0.0066 - val_loss: 0.0126 - val_output_1_loss: 0.0086 - val_output_2_loss: 0.0040 - val_output_1_mean_squared_error: 0.0086 - val_output_2_mean_squared_error: 0.0040\n",
      "Epoch 73/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0375 - output_1_loss: 0.0310 - output_2_loss: 0.0065 - output_1_mean_squared_error: 0.0310 - output_2_mean_squared_error: 0.0065 - val_loss: 0.0103 - val_output_1_loss: 0.0080 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0080 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 74/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0366 - output_1_loss: 0.0304 - output_2_loss: 0.0062 - output_1_mean_squared_error: 0.0304 - output_2_mean_squared_error: 0.0062 - val_loss: 0.0104 - val_output_1_loss: 0.0081 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0081 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 75/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0372 - output_1_loss: 0.0304 - output_2_loss: 0.0067 - output_1_mean_squared_error: 0.0304 - output_2_mean_squared_error: 0.0067 - val_loss: 0.0102 - val_output_1_loss: 0.0081 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0081 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 76/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0369 - output_1_loss: 0.0304 - output_2_loss: 0.0065 - output_1_mean_squared_error: 0.0304 - output_2_mean_squared_error: 0.0065 - val_loss: 0.0099 - val_output_1_loss: 0.0079 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0079 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 77/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0364 - output_1_loss: 0.0300 - output_2_loss: 0.0064 - output_1_mean_squared_error: 0.0300 - output_2_mean_squared_error: 0.0064 - val_loss: 0.0098 - val_output_1_loss: 0.0079 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0079 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 78/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0358 - output_1_loss: 0.0297 - output_2_loss: 0.0061 - output_1_mean_squared_error: 0.0297 - output_2_mean_squared_error: 0.0061 - val_loss: 0.0094 - val_output_1_loss: 0.0074 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0074 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 79/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0359 - output_1_loss: 0.0296 - output_2_loss: 0.0062 - output_1_mean_squared_error: 0.0296 - output_2_mean_squared_error: 0.0062 - val_loss: 0.0097 - val_output_1_loss: 0.0076 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0076 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 80/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0354 - output_1_loss: 0.0296 - output_2_loss: 0.0059 - output_1_mean_squared_error: 0.0296 - output_2_mean_squared_error: 0.0059 - val_loss: 0.0092 - val_output_1_loss: 0.0072 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0072 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 81/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0355 - output_1_loss: 0.0295 - output_2_loss: 0.0061 - output_1_mean_squared_error: 0.0295 - output_2_mean_squared_error: 0.0061 - val_loss: 0.0112 - val_output_1_loss: 0.0078 - val_output_2_loss: 0.0034 - val_output_1_mean_squared_error: 0.0078 - val_output_2_mean_squared_error: 0.0034\n",
      "Epoch 82/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0353 - output_1_loss: 0.0292 - output_2_loss: 0.0061 - output_1_mean_squared_error: 0.0292 - output_2_mean_squared_error: 0.0061 - val_loss: 0.0093 - val_output_1_loss: 0.0073 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0073 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 83/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0350 - output_1_loss: 0.0292 - output_2_loss: 0.0059 - output_1_mean_squared_error: 0.0292 - output_2_mean_squared_error: 0.0059 - val_loss: 0.0095 - val_output_1_loss: 0.0075 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0075 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 84/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0347 - output_1_loss: 0.0289 - output_2_loss: 0.0058 - output_1_mean_squared_error: 0.0289 - output_2_mean_squared_error: 0.0058 - val_loss: 0.0090 - val_output_1_loss: 0.0071 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0071 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 85/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0348 - output_1_loss: 0.0287 - output_2_loss: 0.0062 - output_1_mean_squared_error: 0.0287 - output_2_mean_squared_error: 0.0062 - val_loss: 0.0088 - val_output_1_loss: 0.0068 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0068 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 86/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0341 - output_1_loss: 0.0284 - output_2_loss: 0.0058 - output_1_mean_squared_error: 0.0284 - output_2_mean_squared_error: 0.0058 - val_loss: 0.0093 - val_output_1_loss: 0.0070 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0070 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 87/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0337 - output_1_loss: 0.0280 - output_2_loss: 0.0057 - output_1_mean_squared_error: 0.0280 - output_2_mean_squared_error: 0.0057 - val_loss: 0.0096 - val_output_1_loss: 0.0070 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0070 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 88/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0338 - output_1_loss: 0.0280 - output_2_loss: 0.0058 - output_1_mean_squared_error: 0.0280 - output_2_mean_squared_error: 0.0058 - val_loss: 0.0093 - val_output_1_loss: 0.0070 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0070 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 89/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0334 - output_1_loss: 0.0280 - output_2_loss: 0.0055 - output_1_mean_squared_error: 0.0280 - output_2_mean_squared_error: 0.0055 - val_loss: 0.0101 - val_output_1_loss: 0.0071 - val_output_2_loss: 0.0030 - val_output_1_mean_squared_error: 0.0071 - val_output_2_mean_squared_error: 0.0030\n",
      "Epoch 90/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0333 - output_1_loss: 0.0278 - output_2_loss: 0.0056 - output_1_mean_squared_error: 0.0278 - output_2_mean_squared_error: 0.0056 - val_loss: 0.0085 - val_output_1_loss: 0.0066 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0066 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 91/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0330 - output_1_loss: 0.0274 - output_2_loss: 0.0056 - output_1_mean_squared_error: 0.0274 - output_2_mean_squared_error: 0.0056 - val_loss: 0.0087 - val_output_1_loss: 0.0065 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0065 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 92/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0329 - output_1_loss: 0.0273 - output_2_loss: 0.0057 - output_1_mean_squared_error: 0.0273 - output_2_mean_squared_error: 0.0057 - val_loss: 0.0106 - val_output_1_loss: 0.0074 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0074 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 93/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0328 - output_1_loss: 0.0272 - output_2_loss: 0.0056 - output_1_mean_squared_error: 0.0272 - output_2_mean_squared_error: 0.0056 - val_loss: 0.0096 - val_output_1_loss: 0.0068 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0068 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 94/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0326 - output_1_loss: 0.0271 - output_2_loss: 0.0054 - output_1_mean_squared_error: 0.0271 - output_2_mean_squared_error: 0.0054 - val_loss: 0.0102 - val_output_1_loss: 0.0068 - val_output_2_loss: 0.0034 - val_output_1_mean_squared_error: 0.0068 - val_output_2_mean_squared_error: 0.0034\n",
      "Epoch 95/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0321 - output_1_loss: 0.0269 - output_2_loss: 0.0052 - output_1_mean_squared_error: 0.0269 - output_2_mean_squared_error: 0.0052 - val_loss: 0.0090 - val_output_1_loss: 0.0066 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0066 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 96/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0317 - output_1_loss: 0.0266 - output_2_loss: 0.0052 - output_1_mean_squared_error: 0.0266 - output_2_mean_squared_error: 0.0052 - val_loss: 0.0082 - val_output_1_loss: 0.0062 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0062 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 97/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0318 - output_1_loss: 0.0266 - output_2_loss: 0.0052 - output_1_mean_squared_error: 0.0266 - output_2_mean_squared_error: 0.0052 - val_loss: 0.0097 - val_output_1_loss: 0.0069 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0069 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 98/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0314 - output_1_loss: 0.0263 - output_2_loss: 0.0051 - output_1_mean_squared_error: 0.0263 - output_2_mean_squared_error: 0.0051 - val_loss: 0.0085 - val_output_1_loss: 0.0065 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0065 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 99/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0316 - output_1_loss: 0.0264 - output_2_loss: 0.0052 - output_1_mean_squared_error: 0.0264 - output_2_mean_squared_error: 0.0052 - val_loss: 0.0098 - val_output_1_loss: 0.0065 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0065 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 100/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0313 - output_1_loss: 0.0263 - output_2_loss: 0.0051 - output_1_mean_squared_error: 0.0263 - output_2_mean_squared_error: 0.0051 - val_loss: 0.0082 - val_output_1_loss: 0.0063 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0063 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 101/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0312 - output_1_loss: 0.0261 - output_2_loss: 0.0050 - output_1_mean_squared_error: 0.0261 - output_2_mean_squared_error: 0.0050 - val_loss: 0.0088 - val_output_1_loss: 0.0063 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0063 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 102/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0313 - output_1_loss: 0.0259 - output_2_loss: 0.0054 - output_1_mean_squared_error: 0.0259 - output_2_mean_squared_error: 0.0054 - val_loss: 0.0079 - val_output_1_loss: 0.0059 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0059 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 103/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0306 - output_1_loss: 0.0257 - output_2_loss: 0.0050 - output_1_mean_squared_error: 0.0257 - output_2_mean_squared_error: 0.0050 - val_loss: 0.0085 - val_output_1_loss: 0.0061 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0061 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 104/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0307 - output_1_loss: 0.0258 - output_2_loss: 0.0049 - output_1_mean_squared_error: 0.0258 - output_2_mean_squared_error: 0.0049 - val_loss: 0.0087 - val_output_1_loss: 0.0063 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0063 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 105/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0307 - output_1_loss: 0.0257 - output_2_loss: 0.0050 - output_1_mean_squared_error: 0.0257 - output_2_mean_squared_error: 0.0050 - val_loss: 0.0077 - val_output_1_loss: 0.0059 - val_output_2_loss: 0.0018 - val_output_1_mean_squared_error: 0.0059 - val_output_2_mean_squared_error: 0.0018\n",
      "Epoch 106/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0300 - output_1_loss: 0.0252 - output_2_loss: 0.0048 - output_1_mean_squared_error: 0.0252 - output_2_mean_squared_error: 0.0048 - val_loss: 0.0076 - val_output_1_loss: 0.0057 - val_output_2_loss: 0.0018 - val_output_1_mean_squared_error: 0.0057 - val_output_2_mean_squared_error: 0.0018\n",
      "Epoch 107/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0302 - output_1_loss: 0.0252 - output_2_loss: 0.0049 - output_1_mean_squared_error: 0.0252 - output_2_mean_squared_error: 0.0049 - val_loss: 0.0080 - val_output_1_loss: 0.0059 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0059 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 108/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0297 - output_1_loss: 0.0249 - output_2_loss: 0.0048 - output_1_mean_squared_error: 0.0249 - output_2_mean_squared_error: 0.0048 - val_loss: 0.0078 - val_output_1_loss: 0.0059 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0059 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 109/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0298 - output_1_loss: 0.0250 - output_2_loss: 0.0048 - output_1_mean_squared_error: 0.0250 - output_2_mean_squared_error: 0.0048 - val_loss: 0.0073 - val_output_1_loss: 0.0057 - val_output_2_loss: 0.0017 - val_output_1_mean_squared_error: 0.0057 - val_output_2_mean_squared_error: 0.0017\n",
      "Epoch 110/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0295 - output_1_loss: 0.0246 - output_2_loss: 0.0049 - output_1_mean_squared_error: 0.0246 - output_2_mean_squared_error: 0.0049 - val_loss: 0.0075 - val_output_1_loss: 0.0056 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0056 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 111/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0291 - output_1_loss: 0.0244 - output_2_loss: 0.0047 - output_1_mean_squared_error: 0.0244 - output_2_mean_squared_error: 0.0047 - val_loss: 0.0078 - val_output_1_loss: 0.0059 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0059 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 112/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0291 - output_1_loss: 0.0244 - output_2_loss: 0.0047 - output_1_mean_squared_error: 0.0244 - output_2_mean_squared_error: 0.0047 - val_loss: 0.0074 - val_output_1_loss: 0.0055 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0055 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 113/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0287 - output_1_loss: 0.0241 - output_2_loss: 0.0047 - output_1_mean_squared_error: 0.0241 - output_2_mean_squared_error: 0.0047 - val_loss: 0.0082 - val_output_1_loss: 0.0056 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0056 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 114/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0285 - output_1_loss: 0.0240 - output_2_loss: 0.0045 - output_1_mean_squared_error: 0.0240 - output_2_mean_squared_error: 0.0045 - val_loss: 0.0085 - val_output_1_loss: 0.0058 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0058 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 115/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0286 - output_1_loss: 0.0240 - output_2_loss: 0.0046 - output_1_mean_squared_error: 0.0240 - output_2_mean_squared_error: 0.0046 - val_loss: 0.0085 - val_output_1_loss: 0.0058 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0058 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 116/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0284 - output_1_loss: 0.0238 - output_2_loss: 0.0046 - output_1_mean_squared_error: 0.0238 - output_2_mean_squared_error: 0.0046 - val_loss: 0.0081 - val_output_1_loss: 0.0057 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0057 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 117/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0283 - output_1_loss: 0.0237 - output_2_loss: 0.0045 - output_1_mean_squared_error: 0.0237 - output_2_mean_squared_error: 0.0045 - val_loss: 0.0085 - val_output_1_loss: 0.0057 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0057 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 118/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0277 - output_1_loss: 0.0234 - output_2_loss: 0.0044 - output_1_mean_squared_error: 0.0234 - output_2_mean_squared_error: 0.0044 - val_loss: 0.0076 - val_output_1_loss: 0.0056 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0056 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 119/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0277 - output_1_loss: 0.0234 - output_2_loss: 0.0043 - output_1_mean_squared_error: 0.0234 - output_2_mean_squared_error: 0.0043 - val_loss: 0.0071 - val_output_1_loss: 0.0053 - val_output_2_loss: 0.0017 - val_output_1_mean_squared_error: 0.0053 - val_output_2_mean_squared_error: 0.0017\n",
      "Epoch 120/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0280 - output_1_loss: 0.0235 - output_2_loss: 0.0045 - output_1_mean_squared_error: 0.0235 - output_2_mean_squared_error: 0.0045 - val_loss: 0.0074 - val_output_1_loss: 0.0055 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0055 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 121/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0274 - output_1_loss: 0.0230 - output_2_loss: 0.0044 - output_1_mean_squared_error: 0.0230 - output_2_mean_squared_error: 0.0044 - val_loss: 0.0087 - val_output_1_loss: 0.0055 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0055 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 122/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0273 - output_1_loss: 0.0229 - output_2_loss: 0.0044 - output_1_mean_squared_error: 0.0229 - output_2_mean_squared_error: 0.0044 - val_loss: 0.0086 - val_output_1_loss: 0.0055 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0055 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 123/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0275 - output_1_loss: 0.0229 - output_2_loss: 0.0047 - output_1_mean_squared_error: 0.0229 - output_2_mean_squared_error: 0.0047 - val_loss: 0.0081 - val_output_1_loss: 0.0056 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0056 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 124/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0269 - output_1_loss: 0.0226 - output_2_loss: 0.0043 - output_1_mean_squared_error: 0.0226 - output_2_mean_squared_error: 0.0043 - val_loss: 0.0071 - val_output_1_loss: 0.0053 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0053 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 125/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0269 - output_1_loss: 0.0226 - output_2_loss: 0.0043 - output_1_mean_squared_error: 0.0226 - output_2_mean_squared_error: 0.0043 - val_loss: 0.0091 - val_output_1_loss: 0.0058 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0058 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 126/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0265 - output_1_loss: 0.0223 - output_2_loss: 0.0042 - output_1_mean_squared_error: 0.0223 - output_2_mean_squared_error: 0.0042 - val_loss: 0.0088 - val_output_1_loss: 0.0055 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0055 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 127/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0267 - output_1_loss: 0.0224 - output_2_loss: 0.0043 - output_1_mean_squared_error: 0.0224 - output_2_mean_squared_error: 0.0043 - val_loss: 0.0073 - val_output_1_loss: 0.0056 - val_output_2_loss: 0.0018 - val_output_1_mean_squared_error: 0.0056 - val_output_2_mean_squared_error: 0.0018\n",
      "Epoch 128/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0264 - output_1_loss: 0.0222 - output_2_loss: 0.0042 - output_1_mean_squared_error: 0.0222 - output_2_mean_squared_error: 0.0042 - val_loss: 0.0070 - val_output_1_loss: 0.0052 - val_output_2_loss: 0.0018 - val_output_1_mean_squared_error: 0.0052 - val_output_2_mean_squared_error: 0.0018\n",
      "Epoch 129/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0260 - output_1_loss: 0.0219 - output_2_loss: 0.0040 - output_1_mean_squared_error: 0.0219 - output_2_mean_squared_error: 0.0040 - val_loss: 0.0075 - val_output_1_loss: 0.0052 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0052 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 130/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0263 - output_1_loss: 0.0220 - output_2_loss: 0.0043 - output_1_mean_squared_error: 0.0220 - output_2_mean_squared_error: 0.0043 - val_loss: 0.0068 - val_output_1_loss: 0.0051 - val_output_2_loss: 0.0017 - val_output_1_mean_squared_error: 0.0051 - val_output_2_mean_squared_error: 0.0017\n",
      "Epoch 131/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0257 - output_1_loss: 0.0218 - output_2_loss: 0.0040 - output_1_mean_squared_error: 0.0218 - output_2_mean_squared_error: 0.0040 - val_loss: 0.0072 - val_output_1_loss: 0.0054 - val_output_2_loss: 0.0018 - val_output_1_mean_squared_error: 0.0054 - val_output_2_mean_squared_error: 0.0018\n",
      "Epoch 132/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0258 - output_1_loss: 0.0218 - output_2_loss: 0.0040 - output_1_mean_squared_error: 0.0218 - output_2_mean_squared_error: 0.0040 - val_loss: 0.0074 - val_output_1_loss: 0.0052 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0052 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 133/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0257 - output_1_loss: 0.0216 - output_2_loss: 0.0041 - output_1_mean_squared_error: 0.0216 - output_2_mean_squared_error: 0.0041 - val_loss: 0.0072 - val_output_1_loss: 0.0052 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0052 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 134/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0257 - output_1_loss: 0.0215 - output_2_loss: 0.0042 - output_1_mean_squared_error: 0.0215 - output_2_mean_squared_error: 0.0042 - val_loss: 0.0087 - val_output_1_loss: 0.0055 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0055 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 135/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0255 - output_1_loss: 0.0214 - output_2_loss: 0.0041 - output_1_mean_squared_error: 0.0214 - output_2_mean_squared_error: 0.0041 - val_loss: 0.0080 - val_output_1_loss: 0.0055 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0055 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 136/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0253 - output_1_loss: 0.0212 - output_2_loss: 0.0041 - output_1_mean_squared_error: 0.0212 - output_2_mean_squared_error: 0.0041 - val_loss: 0.0080 - val_output_1_loss: 0.0053 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0053 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 137/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0251 - output_1_loss: 0.0211 - output_2_loss: 0.0040 - output_1_mean_squared_error: 0.0211 - output_2_mean_squared_error: 0.0040 - val_loss: 0.0089 - val_output_1_loss: 0.0050 - val_output_2_loss: 0.0039 - val_output_1_mean_squared_error: 0.0050 - val_output_2_mean_squared_error: 0.0039\n",
      "Epoch 138/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0249 - output_1_loss: 0.0209 - output_2_loss: 0.0040 - output_1_mean_squared_error: 0.0209 - output_2_mean_squared_error: 0.0040 - val_loss: 0.0073 - val_output_1_loss: 0.0049 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0049 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 139/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0251 - output_1_loss: 0.0209 - output_2_loss: 0.0042 - output_1_mean_squared_error: 0.0209 - output_2_mean_squared_error: 0.0042 - val_loss: 0.0073 - val_output_1_loss: 0.0050 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0050 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 140/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0246 - output_1_loss: 0.0208 - output_2_loss: 0.0038 - output_1_mean_squared_error: 0.0208 - output_2_mean_squared_error: 0.0038 - val_loss: 0.0075 - val_output_1_loss: 0.0049 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0049 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 141/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0246 - output_1_loss: 0.0206 - output_2_loss: 0.0040 - output_1_mean_squared_error: 0.0206 - output_2_mean_squared_error: 0.0040 - val_loss: 0.0075 - val_output_1_loss: 0.0052 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0052 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 142/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0242 - output_1_loss: 0.0205 - output_2_loss: 0.0038 - output_1_mean_squared_error: 0.0205 - output_2_mean_squared_error: 0.0038 - val_loss: 0.0077 - val_output_1_loss: 0.0049 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0049 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 143/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0244 - output_1_loss: 0.0204 - output_2_loss: 0.0040 - output_1_mean_squared_error: 0.0204 - output_2_mean_squared_error: 0.0040 - val_loss: 0.0068 - val_output_1_loss: 0.0049 - val_output_2_loss: 0.0018 - val_output_1_mean_squared_error: 0.0049 - val_output_2_mean_squared_error: 0.0018\n",
      "Epoch 144/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0241 - output_1_loss: 0.0204 - output_2_loss: 0.0038 - output_1_mean_squared_error: 0.0204 - output_2_mean_squared_error: 0.0038 - val_loss: 0.0078 - val_output_1_loss: 0.0050 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0050 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 145/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0238 - output_1_loss: 0.0201 - output_2_loss: 0.0037 - output_1_mean_squared_error: 0.0201 - output_2_mean_squared_error: 0.0037 - val_loss: 0.0067 - val_output_1_loss: 0.0048 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0048 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 146/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0239 - output_1_loss: 0.0200 - output_2_loss: 0.0038 - output_1_mean_squared_error: 0.0200 - output_2_mean_squared_error: 0.0038 - val_loss: 0.0074 - val_output_1_loss: 0.0048 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0048 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 147/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0239 - output_1_loss: 0.0201 - output_2_loss: 0.0038 - output_1_mean_squared_error: 0.0201 - output_2_mean_squared_error: 0.0038 - val_loss: 0.0063 - val_output_1_loss: 0.0046 - val_output_2_loss: 0.0016 - val_output_1_mean_squared_error: 0.0046 - val_output_2_mean_squared_error: 0.0016\n",
      "Epoch 148/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0236 - output_1_loss: 0.0197 - output_2_loss: 0.0038 - output_1_mean_squared_error: 0.0197 - output_2_mean_squared_error: 0.0038 - val_loss: 0.0076 - val_output_1_loss: 0.0049 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0049 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 149/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0233 - output_1_loss: 0.0197 - output_2_loss: 0.0036 - output_1_mean_squared_error: 0.0197 - output_2_mean_squared_error: 0.0036 - val_loss: 0.0067 - val_output_1_loss: 0.0047 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0047 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 150/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0237 - output_1_loss: 0.0197 - output_2_loss: 0.0039 - output_1_mean_squared_error: 0.0197 - output_2_mean_squared_error: 0.0039 - val_loss: 0.0082 - val_output_1_loss: 0.0051 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0051 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 151/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0232 - output_1_loss: 0.0195 - output_2_loss: 0.0037 - output_1_mean_squared_error: 0.0195 - output_2_mean_squared_error: 0.0037 - val_loss: 0.0064 - val_output_1_loss: 0.0048 - val_output_2_loss: 0.0016 - val_output_1_mean_squared_error: 0.0048 - val_output_2_mean_squared_error: 0.0016\n",
      "Epoch 152/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0231 - output_1_loss: 0.0193 - output_2_loss: 0.0037 - output_1_mean_squared_error: 0.0193 - output_2_mean_squared_error: 0.0037 - val_loss: 0.0070 - val_output_1_loss: 0.0049 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0049 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 153/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0230 - output_1_loss: 0.0193 - output_2_loss: 0.0037 - output_1_mean_squared_error: 0.0193 - output_2_mean_squared_error: 0.0037 - val_loss: 0.0068 - val_output_1_loss: 0.0047 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0047 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 154/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0228 - output_1_loss: 0.0192 - output_2_loss: 0.0036 - output_1_mean_squared_error: 0.0192 - output_2_mean_squared_error: 0.0036 - val_loss: 0.0069 - val_output_1_loss: 0.0047 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0047 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 155/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0229 - output_1_loss: 0.0193 - output_2_loss: 0.0037 - output_1_mean_squared_error: 0.0193 - output_2_mean_squared_error: 0.0037 - val_loss: 0.0081 - val_output_1_loss: 0.0049 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0049 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 156/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0225 - output_1_loss: 0.0189 - output_2_loss: 0.0036 - output_1_mean_squared_error: 0.0189 - output_2_mean_squared_error: 0.0036 - val_loss: 0.0096 - val_output_1_loss: 0.0051 - val_output_2_loss: 0.0045 - val_output_1_mean_squared_error: 0.0051 - val_output_2_mean_squared_error: 0.0045\n",
      "Epoch 157/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0227 - output_1_loss: 0.0190 - output_2_loss: 0.0037 - output_1_mean_squared_error: 0.0190 - output_2_mean_squared_error: 0.0037 - val_loss: 0.0095 - val_output_1_loss: 0.0051 - val_output_2_loss: 0.0044 - val_output_1_mean_squared_error: 0.0051 - val_output_2_mean_squared_error: 0.0044\n",
      "Epoch 158/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0225 - output_1_loss: 0.0189 - output_2_loss: 0.0036 - output_1_mean_squared_error: 0.0189 - output_2_mean_squared_error: 0.0036 - val_loss: 0.0063 - val_output_1_loss: 0.0045 - val_output_2_loss: 0.0018 - val_output_1_mean_squared_error: 0.0045 - val_output_2_mean_squared_error: 0.0018\n",
      "Epoch 159/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0221 - output_1_loss: 0.0185 - output_2_loss: 0.0036 - output_1_mean_squared_error: 0.0185 - output_2_mean_squared_error: 0.0036 - val_loss: 0.0068 - val_output_1_loss: 0.0047 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0047 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 160/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0222 - output_1_loss: 0.0186 - output_2_loss: 0.0036 - output_1_mean_squared_error: 0.0186 - output_2_mean_squared_error: 0.0036 - val_loss: 0.0081 - val_output_1_loss: 0.0048 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0048 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 161/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0221 - output_1_loss: 0.0185 - output_2_loss: 0.0036 - output_1_mean_squared_error: 0.0185 - output_2_mean_squared_error: 0.0036 - val_loss: 0.0070 - val_output_1_loss: 0.0048 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0048 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 162/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0220 - output_1_loss: 0.0184 - output_2_loss: 0.0036 - output_1_mean_squared_error: 0.0184 - output_2_mean_squared_error: 0.0036 - val_loss: 0.0072 - val_output_1_loss: 0.0048 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0048 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 163/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0217 - output_1_loss: 0.0182 - output_2_loss: 0.0034 - output_1_mean_squared_error: 0.0182 - output_2_mean_squared_error: 0.0034 - val_loss: 0.0066 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0044 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 164/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0217 - output_1_loss: 0.0183 - output_2_loss: 0.0034 - output_1_mean_squared_error: 0.0183 - output_2_mean_squared_error: 0.0034 - val_loss: 0.0069 - val_output_1_loss: 0.0047 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0047 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 165/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0215 - output_1_loss: 0.0181 - output_2_loss: 0.0033 - output_1_mean_squared_error: 0.0181 - output_2_mean_squared_error: 0.0033 - val_loss: 0.0072 - val_output_1_loss: 0.0045 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0045 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 166/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0217 - output_1_loss: 0.0181 - output_2_loss: 0.0036 - output_1_mean_squared_error: 0.0181 - output_2_mean_squared_error: 0.0036 - val_loss: 0.0076 - val_output_1_loss: 0.0047 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0047 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 167/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0213 - output_1_loss: 0.0179 - output_2_loss: 0.0033 - output_1_mean_squared_error: 0.0179 - output_2_mean_squared_error: 0.0033 - val_loss: 0.0065 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0044 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 168/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0214 - output_1_loss: 0.0178 - output_2_loss: 0.0036 - output_1_mean_squared_error: 0.0178 - output_2_mean_squared_error: 0.0036 - val_loss: 0.0067 - val_output_1_loss: 0.0045 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0045 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 169/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0211 - output_1_loss: 0.0179 - output_2_loss: 0.0033 - output_1_mean_squared_error: 0.0179 - output_2_mean_squared_error: 0.0033 - val_loss: 0.0072 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0044 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 170/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0210 - output_1_loss: 0.0177 - output_2_loss: 0.0033 - output_1_mean_squared_error: 0.0177 - output_2_mean_squared_error: 0.0033 - val_loss: 0.0067 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0044 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 171/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0211 - output_1_loss: 0.0176 - output_2_loss: 0.0034 - output_1_mean_squared_error: 0.0176 - output_2_mean_squared_error: 0.0034 - val_loss: 0.0081 - val_output_1_loss: 0.0047 - val_output_2_loss: 0.0034 - val_output_1_mean_squared_error: 0.0047 - val_output_2_mean_squared_error: 0.0034\n",
      "Epoch 172/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0208 - output_1_loss: 0.0174 - output_2_loss: 0.0034 - output_1_mean_squared_error: 0.0174 - output_2_mean_squared_error: 0.0034 - val_loss: 0.0060 - val_output_1_loss: 0.0041 - val_output_2_loss: 0.0018 - val_output_1_mean_squared_error: 0.0041 - val_output_2_mean_squared_error: 0.0018\n",
      "Epoch 173/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0207 - output_1_loss: 0.0174 - output_2_loss: 0.0033 - output_1_mean_squared_error: 0.0174 - output_2_mean_squared_error: 0.0033 - val_loss: 0.0067 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0044 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 174/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0208 - output_1_loss: 0.0174 - output_2_loss: 0.0034 - output_1_mean_squared_error: 0.0174 - output_2_mean_squared_error: 0.0034 - val_loss: 0.0079 - val_output_1_loss: 0.0045 - val_output_2_loss: 0.0034 - val_output_1_mean_squared_error: 0.0045 - val_output_2_mean_squared_error: 0.0034\n",
      "Epoch 175/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0205 - output_1_loss: 0.0173 - output_2_loss: 0.0033 - output_1_mean_squared_error: 0.0173 - output_2_mean_squared_error: 0.0033 - val_loss: 0.0069 - val_output_1_loss: 0.0043 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0043 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 176/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0204 - output_1_loss: 0.0172 - output_2_loss: 0.0031 - output_1_mean_squared_error: 0.0172 - output_2_mean_squared_error: 0.0031 - val_loss: 0.0072 - val_output_1_loss: 0.0045 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0045 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 177/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0202 - output_1_loss: 0.0170 - output_2_loss: 0.0032 - output_1_mean_squared_error: 0.0170 - output_2_mean_squared_error: 0.0032 - val_loss: 0.0070 - val_output_1_loss: 0.0045 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0045 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 178/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0205 - output_1_loss: 0.0172 - output_2_loss: 0.0034 - output_1_mean_squared_error: 0.0172 - output_2_mean_squared_error: 0.0034 - val_loss: 0.0076 - val_output_1_loss: 0.0045 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0045 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 179/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0203 - output_1_loss: 0.0170 - output_2_loss: 0.0033 - output_1_mean_squared_error: 0.0170 - output_2_mean_squared_error: 0.0033 - val_loss: 0.0069 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0044 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 180/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0200 - output_1_loss: 0.0169 - output_2_loss: 0.0031 - output_1_mean_squared_error: 0.0169 - output_2_mean_squared_error: 0.0031 - val_loss: 0.0083 - val_output_1_loss: 0.0045 - val_output_2_loss: 0.0038 - val_output_1_mean_squared_error: 0.0045 - val_output_2_mean_squared_error: 0.0038\n",
      "Epoch 181/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0200 - output_1_loss: 0.0168 - output_2_loss: 0.0033 - output_1_mean_squared_error: 0.0168 - output_2_mean_squared_error: 0.0033 - val_loss: 0.0065 - val_output_1_loss: 0.0042 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0042 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 182/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0195 - output_1_loss: 0.0166 - output_2_loss: 0.0029 - output_1_mean_squared_error: 0.0166 - output_2_mean_squared_error: 0.0029 - val_loss: 0.0073 - val_output_1_loss: 0.0045 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0045 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 183/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0198 - output_1_loss: 0.0166 - output_2_loss: 0.0033 - output_1_mean_squared_error: 0.0166 - output_2_mean_squared_error: 0.0033 - val_loss: 0.0081 - val_output_1_loss: 0.0043 - val_output_2_loss: 0.0038 - val_output_1_mean_squared_error: 0.0043 - val_output_2_mean_squared_error: 0.0038\n",
      "Epoch 184/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0197 - output_1_loss: 0.0165 - output_2_loss: 0.0032 - output_1_mean_squared_error: 0.0165 - output_2_mean_squared_error: 0.0032 - val_loss: 0.0071 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0044 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 185/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0194 - output_1_loss: 0.0163 - output_2_loss: 0.0031 - output_1_mean_squared_error: 0.0163 - output_2_mean_squared_error: 0.0031 - val_loss: 0.0069 - val_output_1_loss: 0.0042 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0042 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 186/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0194 - output_1_loss: 0.0163 - output_2_loss: 0.0031 - output_1_mean_squared_error: 0.0163 - output_2_mean_squared_error: 0.0031 - val_loss: 0.0090 - val_output_1_loss: 0.0046 - val_output_2_loss: 0.0044 - val_output_1_mean_squared_error: 0.0046 - val_output_2_mean_squared_error: 0.0044\n",
      "Epoch 187/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0193 - output_1_loss: 0.0162 - output_2_loss: 0.0030 - output_1_mean_squared_error: 0.0162 - output_2_mean_squared_error: 0.0030 - val_loss: 0.0074 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0030 - val_output_1_mean_squared_error: 0.0044 - val_output_2_mean_squared_error: 0.0030\n",
      "Epoch 188/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0194 - output_1_loss: 0.0164 - output_2_loss: 0.0031 - output_1_mean_squared_error: 0.0164 - output_2_mean_squared_error: 0.0031 - val_loss: 0.0067 - val_output_1_loss: 0.0041 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0041 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 189/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0191 - output_1_loss: 0.0160 - output_2_loss: 0.0030 - output_1_mean_squared_error: 0.0160 - output_2_mean_squared_error: 0.0030 - val_loss: 0.0067 - val_output_1_loss: 0.0043 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0043 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 190/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0192 - output_1_loss: 0.0161 - output_2_loss: 0.0031 - output_1_mean_squared_error: 0.0161 - output_2_mean_squared_error: 0.0031 - val_loss: 0.0075 - val_output_1_loss: 0.0047 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0047 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 191/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0191 - output_1_loss: 0.0160 - output_2_loss: 0.0031 - output_1_mean_squared_error: 0.0160 - output_2_mean_squared_error: 0.0031 - val_loss: 0.0063 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0044 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 192/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0191 - output_1_loss: 0.0160 - output_2_loss: 0.0031 - output_1_mean_squared_error: 0.0160 - output_2_mean_squared_error: 0.0031 - val_loss: 0.0062 - val_output_1_loss: 0.0043 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0043 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 193/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0188 - output_1_loss: 0.0158 - output_2_loss: 0.0030 - output_1_mean_squared_error: 0.0158 - output_2_mean_squared_error: 0.0030 - val_loss: 0.0068 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0044 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 194/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0186 - output_1_loss: 0.0157 - output_2_loss: 0.0030 - output_1_mean_squared_error: 0.0157 - output_2_mean_squared_error: 0.0030 - val_loss: 0.0072 - val_output_1_loss: 0.0045 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0045 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 195/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0188 - output_1_loss: 0.0158 - output_2_loss: 0.0030 - output_1_mean_squared_error: 0.0158 - output_2_mean_squared_error: 0.0030 - val_loss: 0.0067 - val_output_1_loss: 0.0041 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0041 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 196/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0186 - output_1_loss: 0.0157 - output_2_loss: 0.0029 - output_1_mean_squared_error: 0.0157 - output_2_mean_squared_error: 0.0029 - val_loss: 0.0066 - val_output_1_loss: 0.0042 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0042 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 197/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0190 - output_1_loss: 0.0158 - output_2_loss: 0.0032 - output_1_mean_squared_error: 0.0158 - output_2_mean_squared_error: 0.0032 - val_loss: 0.0082 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0037 - val_output_1_mean_squared_error: 0.0044 - val_output_2_mean_squared_error: 0.0037\n",
      "Epoch 198/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0184 - output_1_loss: 0.0155 - output_2_loss: 0.0029 - output_1_mean_squared_error: 0.0155 - output_2_mean_squared_error: 0.0029 - val_loss: 0.0068 - val_output_1_loss: 0.0043 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0043 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 199/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0189 - output_1_loss: 0.0156 - output_2_loss: 0.0032 - output_1_mean_squared_error: 0.0156 - output_2_mean_squared_error: 0.0032 - val_loss: 0.0072 - val_output_1_loss: 0.0043 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0043 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 200/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0185 - output_1_loss: 0.0155 - output_2_loss: 0.0030 - output_1_mean_squared_error: 0.0155 - output_2_mean_squared_error: 0.0030 - val_loss: 0.0079 - val_output_1_loss: 0.0045 - val_output_2_loss: 0.0035 - val_output_1_mean_squared_error: 0.0045 - val_output_2_mean_squared_error: 0.0035\n",
      "Epoch 201/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0186 - output_1_loss: 0.0154 - output_2_loss: 0.0032 - output_1_mean_squared_error: 0.0154 - output_2_mean_squared_error: 0.0032 - val_loss: 0.0081 - val_output_1_loss: 0.0043 - val_output_2_loss: 0.0039 - val_output_1_mean_squared_error: 0.0043 - val_output_2_mean_squared_error: 0.0039\n",
      "Epoch 202/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0181 - output_1_loss: 0.0152 - output_2_loss: 0.0029 - output_1_mean_squared_error: 0.0152 - output_2_mean_squared_error: 0.0029 - val_loss: 0.0062 - val_output_1_loss: 0.0041 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0041 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 203/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0184 - output_1_loss: 0.0153 - output_2_loss: 0.0030 - output_1_mean_squared_error: 0.0153 - output_2_mean_squared_error: 0.0030 - val_loss: 0.0074 - val_output_1_loss: 0.0043 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0043 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 204/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0180 - output_1_loss: 0.0151 - output_2_loss: 0.0029 - output_1_mean_squared_error: 0.0151 - output_2_mean_squared_error: 0.0029 - val_loss: 0.0084 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0040 - val_output_1_mean_squared_error: 0.0044 - val_output_2_mean_squared_error: 0.0040\n",
      "Epoch 205/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0181 - output_1_loss: 0.0151 - output_2_loss: 0.0031 - output_1_mean_squared_error: 0.0151 - output_2_mean_squared_error: 0.0031 - val_loss: 0.0084 - val_output_1_loss: 0.0044 - val_output_2_loss: 0.0040 - val_output_1_mean_squared_error: 0.0044 - val_output_2_mean_squared_error: 0.0040\n",
      "Epoch 206/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0179 - output_1_loss: 0.0150 - output_2_loss: 0.0030 - output_1_mean_squared_error: 0.0150 - output_2_mean_squared_error: 0.0030 - val_loss: 0.0068 - val_output_1_loss: 0.0042 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0042 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 207/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0178 - output_1_loss: 0.0150 - output_2_loss: 0.0028 - output_1_mean_squared_error: 0.0150 - output_2_mean_squared_error: 0.0028 - val_loss: 0.0063 - val_output_1_loss: 0.0041 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0041 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 208/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0177 - output_1_loss: 0.0149 - output_2_loss: 0.0028 - output_1_mean_squared_error: 0.0149 - output_2_mean_squared_error: 0.0028 - val_loss: 0.0067 - val_output_1_loss: 0.0042 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0042 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 209/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0178 - output_1_loss: 0.0149 - output_2_loss: 0.0029 - output_1_mean_squared_error: 0.0149 - output_2_mean_squared_error: 0.0029 - val_loss: 0.0063 - val_output_1_loss: 0.0042 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0042 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 210/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0178 - output_1_loss: 0.0149 - output_2_loss: 0.0029 - output_1_mean_squared_error: 0.0149 - output_2_mean_squared_error: 0.0029 - val_loss: 0.0071 - val_output_1_loss: 0.0040 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0040 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 211/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0176 - output_1_loss: 0.0148 - output_2_loss: 0.0028 - output_1_mean_squared_error: 0.0148 - output_2_mean_squared_error: 0.0028 - val_loss: 0.0067 - val_output_1_loss: 0.0043 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0043 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 212/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0177 - output_1_loss: 0.0148 - output_2_loss: 0.0029 - output_1_mean_squared_error: 0.0148 - output_2_mean_squared_error: 0.0029 - val_loss: 0.0075 - val_output_1_loss: 0.0042 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0042 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 213/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0175 - output_1_loss: 0.0147 - output_2_loss: 0.0028 - output_1_mean_squared_error: 0.0147 - output_2_mean_squared_error: 0.0028 - val_loss: 0.0067 - val_output_1_loss: 0.0043 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0043 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 214/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0172 - output_1_loss: 0.0145 - output_2_loss: 0.0028 - output_1_mean_squared_error: 0.0145 - output_2_mean_squared_error: 0.0028 - val_loss: 0.0073 - val_output_1_loss: 0.0042 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0042 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 215/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0171 - output_1_loss: 0.0144 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0144 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0059 - val_output_1_loss: 0.0041 - val_output_2_loss: 0.0017 - val_output_1_mean_squared_error: 0.0041 - val_output_2_mean_squared_error: 0.0017\n",
      "Epoch 216/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0176 - output_1_loss: 0.0146 - output_2_loss: 0.0030 - output_1_mean_squared_error: 0.0146 - output_2_mean_squared_error: 0.0030 - val_loss: 0.0067 - val_output_1_loss: 0.0042 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0042 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 217/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0172 - output_1_loss: 0.0143 - output_2_loss: 0.0029 - output_1_mean_squared_error: 0.0143 - output_2_mean_squared_error: 0.0029 - val_loss: 0.0072 - val_output_1_loss: 0.0041 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0041 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 218/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0171 - output_1_loss: 0.0143 - output_2_loss: 0.0029 - output_1_mean_squared_error: 0.0143 - output_2_mean_squared_error: 0.0029 - val_loss: 0.0066 - val_output_1_loss: 0.0042 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0042 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 219/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0170 - output_1_loss: 0.0142 - output_2_loss: 0.0028 - output_1_mean_squared_error: 0.0142 - output_2_mean_squared_error: 0.0028 - val_loss: 0.0076 - val_output_1_loss: 0.0043 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0043 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 220/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0170 - output_1_loss: 0.0143 - output_2_loss: 0.0028 - output_1_mean_squared_error: 0.0143 - output_2_mean_squared_error: 0.0028 - val_loss: 0.0055 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0017 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0017\n",
      "Epoch 221/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0170 - output_1_loss: 0.0143 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0143 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0066 - val_output_1_loss: 0.0040 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0040 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 222/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0167 - output_1_loss: 0.0140 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0140 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0075 - val_output_1_loss: 0.0042 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0042 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 223/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0170 - output_1_loss: 0.0142 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0142 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0065 - val_output_1_loss: 0.0041 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0041 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 224/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0170 - output_1_loss: 0.0141 - output_2_loss: 0.0029 - output_1_mean_squared_error: 0.0141 - output_2_mean_squared_error: 0.0029 - val_loss: 0.0061 - val_output_1_loss: 0.0041 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0041 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 225/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0169 - output_1_loss: 0.0141 - output_2_loss: 0.0028 - output_1_mean_squared_error: 0.0141 - output_2_mean_squared_error: 0.0028 - val_loss: 0.0065 - val_output_1_loss: 0.0040 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0040 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 226/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0167 - output_1_loss: 0.0140 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0140 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0061 - val_output_1_loss: 0.0041 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0041 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 227/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0166 - output_1_loss: 0.0139 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0139 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0060 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 228/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0164 - output_1_loss: 0.0138 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0138 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0072 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 229/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0165 - output_1_loss: 0.0138 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0138 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0059 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 230/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0164 - output_1_loss: 0.0137 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0137 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0061 - val_output_1_loss: 0.0041 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0041 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 231/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0164 - output_1_loss: 0.0137 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0137 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0064 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 232/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0164 - output_1_loss: 0.0137 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0137 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0073 - val_output_1_loss: 0.0040 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0040 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 233/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0164 - output_1_loss: 0.0137 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0137 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0066 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 234/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0164 - output_1_loss: 0.0136 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0136 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0082 - val_output_1_loss: 0.0040 - val_output_2_loss: 0.0042 - val_output_1_mean_squared_error: 0.0040 - val_output_2_mean_squared_error: 0.0042\n",
      "Epoch 235/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0161 - output_1_loss: 0.0135 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0135 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0068 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 236/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0161 - output_1_loss: 0.0134 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0134 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0057 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 237/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0161 - output_1_loss: 0.0135 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0135 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0064 - val_output_1_loss: 0.0040 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0040 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 238/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0161 - output_1_loss: 0.0134 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0134 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0057 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 239/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0158 - output_1_loss: 0.0133 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0133 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0068 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 240/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0160 - output_1_loss: 0.0133 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0133 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0057 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 241/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0159 - output_1_loss: 0.0133 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0133 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0058 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 242/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0158 - output_1_loss: 0.0132 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0132 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0076 - val_output_1_loss: 0.0040 - val_output_2_loss: 0.0035 - val_output_1_mean_squared_error: 0.0040 - val_output_2_mean_squared_error: 0.0035\n",
      "Epoch 243/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0157 - output_1_loss: 0.0131 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0131 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0059 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 244/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0158 - output_1_loss: 0.0131 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0131 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0074 - val_output_1_loss: 0.0042 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0042 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 245/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0157 - output_1_loss: 0.0130 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0130 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0072 - val_output_1_loss: 0.0041 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0041 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 246/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0155 - output_1_loss: 0.0129 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0129 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0054 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0017 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0017\n",
      "Epoch 247/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0156 - output_1_loss: 0.0131 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0131 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0052 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0016 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0016\n",
      "Epoch 248/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0156 - output_1_loss: 0.0129 - output_2_loss: 0.0027 - output_1_mean_squared_error: 0.0129 - output_2_mean_squared_error: 0.0027 - val_loss: 0.0073 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0034 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0034\n",
      "Epoch 249/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0154 - output_1_loss: 0.0128 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0128 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0052 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0015 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0015\n",
      "Epoch 250/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0155 - output_1_loss: 0.0127 - output_2_loss: 0.0028 - output_1_mean_squared_error: 0.0127 - output_2_mean_squared_error: 0.0028 - val_loss: 0.0074 - val_output_1_loss: 0.0041 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0041 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 251/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0154 - output_1_loss: 0.0128 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0128 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0074 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0035 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0035\n",
      "Epoch 252/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0151 - output_1_loss: 0.0125 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0125 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0055 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0016 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0016\n",
      "Epoch 253/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0152 - output_1_loss: 0.0127 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0127 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0067 - val_output_1_loss: 0.0040 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0040 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 254/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0152 - output_1_loss: 0.0126 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0126 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0070 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 255/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0150 - output_1_loss: 0.0125 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0125 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0070 - val_output_1_loss: 0.0040 - val_output_2_loss: 0.0030 - val_output_1_mean_squared_error: 0.0040 - val_output_2_mean_squared_error: 0.0030\n",
      "Epoch 256/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0151 - output_1_loss: 0.0126 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0126 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0067 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 257/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0151 - output_1_loss: 0.0125 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0125 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0067 - val_output_1_loss: 0.0040 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0040 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 258/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0149 - output_1_loss: 0.0124 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0124 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0065 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 259/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0147 - output_1_loss: 0.0123 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0123 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0064 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 260/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0150 - output_1_loss: 0.0124 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0124 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0056 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 261/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0147 - output_1_loss: 0.0123 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0123 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0059 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 262/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0149 - output_1_loss: 0.0124 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0124 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0063 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 263/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0147 - output_1_loss: 0.0122 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0122 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0052 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0015 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0015\n",
      "Epoch 264/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0148 - output_1_loss: 0.0123 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0123 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0076 - val_output_1_loss: 0.0040 - val_output_2_loss: 0.0035 - val_output_1_mean_squared_error: 0.0040 - val_output_2_mean_squared_error: 0.0035\n",
      "Epoch 265/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0147 - output_1_loss: 0.0121 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0121 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0071 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 266/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0146 - output_1_loss: 0.0121 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0121 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0082 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0045 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0045\n",
      "Epoch 267/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0146 - output_1_loss: 0.0121 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0121 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0078 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0039 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0039\n",
      "Epoch 268/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0146 - output_1_loss: 0.0121 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0121 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0066 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 269/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0144 - output_1_loss: 0.0119 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0119 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0070 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 270/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0143 - output_1_loss: 0.0119 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0119 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0060 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 271/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0144 - output_1_loss: 0.0119 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0119 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0071 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 272/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0146 - output_1_loss: 0.0120 - output_2_loss: 0.0026 - output_1_mean_squared_error: 0.0120 - output_2_mean_squared_error: 0.0026 - val_loss: 0.0069 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 273/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0143 - output_1_loss: 0.0118 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0118 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0060 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 274/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0143 - output_1_loss: 0.0119 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0119 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0074 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0037 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0037\n",
      "Epoch 275/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0142 - output_1_loss: 0.0118 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0118 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0057 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 276/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0141 - output_1_loss: 0.0117 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0117 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0061 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 277/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0140 - output_1_loss: 0.0116 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0116 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0069 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 278/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0141 - output_1_loss: 0.0118 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0118 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0076 - val_output_1_loss: 0.0042 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0042 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 279/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0140 - output_1_loss: 0.0116 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0116 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0064 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 280/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0140 - output_1_loss: 0.0116 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0116 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0072 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 281/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0139 - output_1_loss: 0.0116 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0116 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0075 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0037 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0037\n",
      "Epoch 282/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0138 - output_1_loss: 0.0114 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0114 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0072 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0034 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0034\n",
      "Epoch 283/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0140 - output_1_loss: 0.0116 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0116 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0057 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 284/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0138 - output_1_loss: 0.0115 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0115 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0068 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 285/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0136 - output_1_loss: 0.0113 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0113 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0065 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 286/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0139 - output_1_loss: 0.0115 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0115 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0068 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0030 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0030\n",
      "Epoch 287/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0137 - output_1_loss: 0.0114 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0114 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0057 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 288/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0137 - output_1_loss: 0.0114 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0114 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0056 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 289/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0138 - output_1_loss: 0.0114 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0114 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0064 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 290/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0137 - output_1_loss: 0.0114 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0114 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0066 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 291/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0137 - output_1_loss: 0.0113 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0113 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0078 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0040 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0040\n",
      "Epoch 292/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0137 - output_1_loss: 0.0112 - output_2_loss: 0.0025 - output_1_mean_squared_error: 0.0112 - output_2_mean_squared_error: 0.0025 - val_loss: 0.0056 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 293/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0138 - output_1_loss: 0.0114 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0114 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0075 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0037 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0037\n",
      "Epoch 294/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0135 - output_1_loss: 0.0112 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0112 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0072 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0034 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0034\n",
      "Epoch 295/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0134 - output_1_loss: 0.0112 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0112 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0067 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0030 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0030\n",
      "Epoch 296/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0136 - output_1_loss: 0.0112 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0112 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0078 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0039 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0039\n",
      "Epoch 297/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0134 - output_1_loss: 0.0110 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0110 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0061 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 298/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0134 - output_1_loss: 0.0111 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0111 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0065 - val_output_1_loss: 0.0039 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0039 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 299/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0132 - output_1_loss: 0.0110 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0110 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0057 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 300/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0132 - output_1_loss: 0.0110 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0110 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0062 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 301/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0133 - output_1_loss: 0.0110 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0110 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0077 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0039 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0039\n",
      "Epoch 302/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0135 - output_1_loss: 0.0111 - output_2_loss: 0.0024 - output_1_mean_squared_error: 0.0111 - output_2_mean_squared_error: 0.0024 - val_loss: 0.0062 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 303/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0133 - output_1_loss: 0.0110 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0110 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0069 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 304/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0132 - output_1_loss: 0.0110 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0110 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0057 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 305/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0132 - output_1_loss: 0.0110 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0110 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0059 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 306/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0132 - output_1_loss: 0.0110 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0110 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0068 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0030 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0030\n",
      "Epoch 307/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0130 - output_1_loss: 0.0108 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0108 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0071 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 308/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0130 - output_1_loss: 0.0107 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0107 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0064 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 309/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0129 - output_1_loss: 0.0107 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0107 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0063 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 310/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0132 - output_1_loss: 0.0109 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0109 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0058 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 311/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0130 - output_1_loss: 0.0108 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0108 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0057 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 312/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0127 - output_1_loss: 0.0105 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0105 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0065 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 313/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0129 - output_1_loss: 0.0107 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0107 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0074 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0036 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0036\n",
      "Epoch 314/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0130 - output_1_loss: 0.0107 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0107 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0070 - val_output_1_loss: 0.0040 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0040 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 315/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0129 - output_1_loss: 0.0106 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0106 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0066 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 316/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0129 - output_1_loss: 0.0107 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0107 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0055 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 317/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0129 - output_1_loss: 0.0106 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0106 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0070 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 318/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0127 - output_1_loss: 0.0105 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0105 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0069 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 319/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0127 - output_1_loss: 0.0105 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0105 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0062 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 320/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0127 - output_1_loss: 0.0105 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0105 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0065 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 321/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0126 - output_1_loss: 0.0104 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0104 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0065 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 322/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0126 - output_1_loss: 0.0104 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0104 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0052 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0017 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0017\n",
      "Epoch 323/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0127 - output_1_loss: 0.0104 - output_2_loss: 0.0023 - output_1_mean_squared_error: 0.0104 - output_2_mean_squared_error: 0.0023 - val_loss: 0.0079 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0041 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0041\n",
      "Epoch 324/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0124 - output_1_loss: 0.0103 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0103 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0056 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 325/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0124 - output_1_loss: 0.0103 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0103 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0068 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 326/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0126 - output_1_loss: 0.0103 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0103 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0068 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 327/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0126 - output_1_loss: 0.0104 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0104 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0058 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 328/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0124 - output_1_loss: 0.0103 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0103 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0058 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 329/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0124 - output_1_loss: 0.0103 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0103 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0065 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 330/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0124 - output_1_loss: 0.0103 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0103 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0054 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 331/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0124 - output_1_loss: 0.0103 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0103 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0052 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 332/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0124 - output_1_loss: 0.0103 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0103 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0068 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 333/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0123 - output_1_loss: 0.0102 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0102 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0075 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0037 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0037\n",
      "Epoch 334/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0121 - output_1_loss: 0.0100 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0100 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0065 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 335/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0123 - output_1_loss: 0.0101 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0101 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0060 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 336/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0121 - output_1_loss: 0.0101 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0101 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0047 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0014 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0014\n",
      "Epoch 337/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0122 - output_1_loss: 0.0100 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0100 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0055 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 338/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0122 - output_1_loss: 0.0100 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0100 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0051 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0017 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0017\n",
      "Epoch 339/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0120 - output_1_loss: 0.0100 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0100 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0066 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 340/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0122 - output_1_loss: 0.0101 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0101 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0058 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 341/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0121 - output_1_loss: 0.0100 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0100 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0061 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 342/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0119 - output_1_loss: 0.0099 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0099 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0055 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 343/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0121 - output_1_loss: 0.0099 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0099 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0060 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 344/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0120 - output_1_loss: 0.0099 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0099 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0060 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 345/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0119 - output_1_loss: 0.0099 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0099 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0059 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 346/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0121 - output_1_loss: 0.0099 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0099 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0075 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0038 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0038\n",
      "Epoch 347/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0120 - output_1_loss: 0.0099 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0099 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0065 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0030 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0030\n",
      "Epoch 348/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0120 - output_1_loss: 0.0099 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0099 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0078 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0041 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0041\n",
      "Epoch 349/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0118 - output_1_loss: 0.0097 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0097 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0061 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 350/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0118 - output_1_loss: 0.0098 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0098 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0060 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 351/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0119 - output_1_loss: 0.0098 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0098 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0061 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 352/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0118 - output_1_loss: 0.0098 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0098 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0055 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 353/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0118 - output_1_loss: 0.0097 - output_2_loss: 0.0022 - output_1_mean_squared_error: 0.0097 - output_2_mean_squared_error: 0.0022 - val_loss: 0.0067 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 354/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0118 - output_1_loss: 0.0098 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0098 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0057 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 355/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0118 - output_1_loss: 0.0097 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0097 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0060 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 356/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0117 - output_1_loss: 0.0097 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0097 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0064 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 357/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0117 - output_1_loss: 0.0096 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0096 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0056 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 358/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0117 - output_1_loss: 0.0096 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0096 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0074 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0036 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0036\n",
      "Epoch 359/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0117 - output_1_loss: 0.0097 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0097 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0063 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 360/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0117 - output_1_loss: 0.0097 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0097 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0057 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 361/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0117 - output_1_loss: 0.0096 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0096 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0061 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 362/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0115 - output_1_loss: 0.0095 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0095 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0060 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 363/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0115 - output_1_loss: 0.0095 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0095 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0051 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0016 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0016\n",
      "Epoch 364/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0115 - output_1_loss: 0.0095 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0095 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0056 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 365/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0115 - output_1_loss: 0.0095 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0095 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0055 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 366/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0114 - output_1_loss: 0.0095 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0095 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0056 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 367/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0113 - output_1_loss: 0.0094 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0094 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0074 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0039 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0039\n",
      "Epoch 368/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0115 - output_1_loss: 0.0095 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0095 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0057 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 369/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0114 - output_1_loss: 0.0094 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0094 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0060 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 370/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0115 - output_1_loss: 0.0094 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0094 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0073 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0038 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0038\n",
      "Epoch 371/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0114 - output_1_loss: 0.0094 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0094 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0068 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 372/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0115 - output_1_loss: 0.0095 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0095 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0067 - val_output_1_loss: 0.0038 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0038 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 373/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0113 - output_1_loss: 0.0093 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0093 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0063 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 374/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0113 - output_1_loss: 0.0093 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0093 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0055 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 375/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0111 - output_1_loss: 0.0092 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0092 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0068 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 376/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0111 - output_1_loss: 0.0092 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0092 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0053 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0020\n",
      "Epoch 377/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0115 - output_1_loss: 0.0094 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0094 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0065 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 378/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0112 - output_1_loss: 0.0092 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0092 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0058 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 379/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0112 - output_1_loss: 0.0093 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0093 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0071 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0036 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0036\n",
      "Epoch 380/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0113 - output_1_loss: 0.0092 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0092 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0063 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 381/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0112 - output_1_loss: 0.0092 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0092 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0051 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0018 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0018\n",
      "Epoch 382/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0110 - output_1_loss: 0.0091 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0091 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0077 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0039 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0039\n",
      "Epoch 383/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0113 - output_1_loss: 0.0093 - output_2_loss: 0.0021 - output_1_mean_squared_error: 0.0093 - output_2_mean_squared_error: 0.0021 - val_loss: 0.0055 - val_output_1_loss: 0.0032 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0032 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 384/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0111 - output_1_loss: 0.0091 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0091 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0062 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 385/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0109 - output_1_loss: 0.0089 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0089 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0057 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 386/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0112 - output_1_loss: 0.0092 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0092 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0059 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 387/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0111 - output_1_loss: 0.0092 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0092 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0060 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 388/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0109 - output_1_loss: 0.0090 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0090 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0058 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 389/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0110 - output_1_loss: 0.0091 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0091 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0066 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 390/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0110 - output_1_loss: 0.0090 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0090 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0048 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0015 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0015\n",
      "Epoch 391/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0110 - output_1_loss: 0.0090 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0090 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0060 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 392/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0110 - output_1_loss: 0.0091 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0091 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0067 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 393/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0111 - output_1_loss: 0.0091 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0091 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0067 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 394/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0109 - output_1_loss: 0.0090 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0090 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0069 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0033 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0033\n",
      "Epoch 395/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0109 - output_1_loss: 0.0090 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0090 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0070 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0035 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0035\n",
      "Epoch 396/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0109 - output_1_loss: 0.0090 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0090 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0063 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 397/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0107 - output_1_loss: 0.0089 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0089 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0063 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 398/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0107 - output_1_loss: 0.0088 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0088 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0054 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 399/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0107 - output_1_loss: 0.0088 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0088 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0056 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 400/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0108 - output_1_loss: 0.0088 - output_2_loss: 0.0020 - output_1_mean_squared_error: 0.0088 - output_2_mean_squared_error: 0.0020 - val_loss: 0.0064 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 401/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0108 - output_1_loss: 0.0090 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0090 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0057 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 402/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0108 - output_1_loss: 0.0089 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0089 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0058 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0023 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0023\n",
      "Epoch 403/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0108 - output_1_loss: 0.0089 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0089 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0055 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 404/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0107 - output_1_loss: 0.0088 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0088 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0058 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 405/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0107 - output_1_loss: 0.0088 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0088 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0062 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 406/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0107 - output_1_loss: 0.0088 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0088 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0053 - val_output_1_loss: 0.0032 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0032 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 407/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0107 - output_1_loss: 0.0088 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0088 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0065 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0029 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0029\n",
      "Epoch 408/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0106 - output_1_loss: 0.0087 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0087 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0066 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0031 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0031\n",
      "Epoch 409/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0106 - output_1_loss: 0.0087 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0087 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0059 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0026 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0026\n",
      "Epoch 410/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0106 - output_1_loss: 0.0088 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0088 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0072 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0037 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0037\n",
      "Epoch 411/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0105 - output_1_loss: 0.0087 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0087 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0070 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0036 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0036\n",
      "Epoch 412/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0104 - output_1_loss: 0.0085 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0085 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0052 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 413/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0105 - output_1_loss: 0.0087 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0087 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0065 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0030 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0030\n",
      "Epoch 414/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0105 - output_1_loss: 0.0087 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0087 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0060 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 415/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0105 - output_1_loss: 0.0086 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0086 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0059 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 416/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0106 - output_1_loss: 0.0088 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0088 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0057 - val_output_1_loss: 0.0032 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0032 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 417/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0106 - output_1_loss: 0.0087 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0087 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0059 - val_output_1_loss: 0.0032 - val_output_2_loss: 0.0027 - val_output_1_mean_squared_error: 0.0032 - val_output_2_mean_squared_error: 0.0027\n",
      "Epoch 418/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0105 - output_1_loss: 0.0087 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0087 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0059 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 419/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0105 - output_1_loss: 0.0086 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0086 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0053 - val_output_1_loss: 0.0032 - val_output_2_loss: 0.0021 - val_output_1_mean_squared_error: 0.0032 - val_output_2_mean_squared_error: 0.0021\n",
      "Epoch 420/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0104 - output_1_loss: 0.0085 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0085 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0058 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 421/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0104 - output_1_loss: 0.0086 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0086 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0051 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0019 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0019\n",
      "Epoch 422/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0104 - output_1_loss: 0.0085 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0085 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0056 - val_output_1_loss: 0.0032 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0032 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 423/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0105 - output_1_loss: 0.0086 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0086 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0055 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 424/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0104 - output_1_loss: 0.0086 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0086 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0082 - val_output_1_loss: 0.0037 - val_output_2_loss: 0.0045 - val_output_1_mean_squared_error: 0.0037 - val_output_2_mean_squared_error: 0.0045\n",
      "Epoch 425/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0106 - output_1_loss: 0.0087 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0087 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0057 - val_output_1_loss: 0.0032 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0032 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 426/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0103 - output_1_loss: 0.0085 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0085 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0069 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0035 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0035\n",
      "Epoch 427/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0105 - output_1_loss: 0.0086 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0086 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0048 - val_output_1_loss: 0.0031 - val_output_2_loss: 0.0017 - val_output_1_mean_squared_error: 0.0031 - val_output_2_mean_squared_error: 0.0017\n",
      "Epoch 428/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0103 - output_1_loss: 0.0084 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0084 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0047 - val_output_1_loss: 0.0032 - val_output_2_loss: 0.0015 - val_output_1_mean_squared_error: 0.0032 - val_output_2_mean_squared_error: 0.0015\n",
      "Epoch 429/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0105 - output_1_loss: 0.0086 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0086 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0065 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0030 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0030\n",
      "Epoch 430/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0103 - output_1_loss: 0.0085 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0085 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0067 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0032 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0032\n",
      "Epoch 431/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0103 - output_1_loss: 0.0084 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0084 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0063 - val_output_1_loss: 0.0035 - val_output_2_loss: 0.0028 - val_output_1_mean_squared_error: 0.0035 - val_output_2_mean_squared_error: 0.0028\n",
      "Epoch 432/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0102 - output_1_loss: 0.0084 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0084 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0060 - val_output_1_loss: 0.0036 - val_output_2_loss: 0.0024 - val_output_1_mean_squared_error: 0.0036 - val_output_2_mean_squared_error: 0.0024\n",
      "Epoch 433/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0103 - output_1_loss: 0.0084 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0084 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0068 - val_output_1_loss: 0.0034 - val_output_2_loss: 0.0034 - val_output_1_mean_squared_error: 0.0034 - val_output_2_mean_squared_error: 0.0034\n",
      "Epoch 434/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0103 - output_1_loss: 0.0084 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0084 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0058 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0025 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0025\n",
      "Epoch 435/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0102 - output_1_loss: 0.0084 - output_2_loss: 0.0018 - output_1_mean_squared_error: 0.0084 - output_2_mean_squared_error: 0.0018 - val_loss: 0.0055 - val_output_1_loss: 0.0032 - val_output_2_loss: 0.0022 - val_output_1_mean_squared_error: 0.0032 - val_output_2_mean_squared_error: 0.0022\n",
      "Epoch 436/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0102 - output_1_loss: 0.0084 - output_2_loss: 0.0019 - output_1_mean_squared_error: 0.0084 - output_2_mean_squared_error: 0.0019 - val_loss: 0.0053 - val_output_1_loss: 0.0033 - val_output_2_loss: 0.0020 - val_output_1_mean_squared_error: 0.0033 - val_output_2_mean_squared_error: 0.0020\n"
     ]
    }
   ],
   "source": [
    "resnet_model.compile(**train_config)\n",
    "history = resnet_model.fit( x = X_train, y = y_train,\n",
    "                           **fit_config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ewO1AkEGqhSo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot()\n",
    "\n",
    "# print((\"Best Validation Loss: {:0.4f}\" +\\\n",
    "#       \"\\nBest Validation Accuracy: {:0.4f}\")\\\n",
    "#       .format(history_df['val_loss'].min(),\n",
    "#               history_df['val_sparse_categorical_accuracy'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "woSCp9TnKiXL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 492us/step\n",
      "mse -- 0.0015773550258433343\n",
      "188/188 [==============================] - 0s 383us/step\n",
      "mse -- 0.0031976336934833303\n"
     ]
    }
   ],
   "source": [
    "def NN_mse(X, y):\n",
    "    hidden, preds = resnet_model.predict(X)\n",
    "    mse = mean_squared_error(y, preds)\n",
    "    print(f'mse -- {mse}')\n",
    "    return mse\n",
    "\n",
    "NN_accuracy_test = NN_mse(X_test, y_test)\n",
    "NN_accuracy_shift = NN_mse(X_shift, y_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ml_5MJViuK77"
   },
   "outputs": [],
   "source": [
    "# SNGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OSRQNhU3M7oK"
   },
   "outputs": [],
   "source": [
    "class DeepResNetSNGP(DeepResNet):\n",
    "  def __init__(self, spec_norm_bound=0.9, **kwargs):\n",
    "    self.spec_norm_bound = spec_norm_bound\n",
    "    super().__init__(**kwargs)\n",
    "\n",
    "  def make_dense_layer(self):\n",
    "    \"\"\"Applies spectral normalization to the hidden layer.\"\"\"\n",
    "    dense_layer = super().make_dense_layer()\n",
    "    return nlp_layers.SpectralNormalization(\n",
    "        dense_layer, norm_multiplier=self.spec_norm_bound)\n",
    "\n",
    "  def make_output_layer(self, num_classes):\n",
    "    \"\"\"Uses Gaussian process as the output layer.\"\"\"\n",
    "    return nlp_layers.RandomFeatureGaussianProcess(\n",
    "        num_classes,\n",
    "        gp_kernel_scale = 100.0,\n",
    "        gp_cov_momentum=-1,\n",
    "        **self.classifier_kwargs)\n",
    "\n",
    "  def call(self, inputs, training=False, return_covmat=False):\n",
    "    # Gets logits and a covariance matrix from the GP layer.\n",
    "    hidden, (logits, covmat) = super().call(inputs)\n",
    "\n",
    "    # Returns only logits during training.\n",
    "    if not training and return_covmat:\n",
    "      return hidden, logits, covmat\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2hTnGAmeM7zB"
   },
   "outputs": [],
   "source": [
    "# Implement a Keras callback to reset the covariance matrix at the beginning of a new epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZUhuvEyRM71Y"
   },
   "outputs": [],
   "source": [
    "class ResetCovarianceCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_begin(self, epoch, logs=None):\n",
    "    \"\"\"Resets covariance matrix at the beginning of the epoch.\"\"\"\n",
    "    if epoch > 0:\n",
    "      self.model.classifier.reset_covariance_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wjo8PSYdh1T-"
   },
   "outputs": [],
   "source": [
    "class DeepResNetSNGPWithCovReset(DeepResNetSNGP):\n",
    "  def fit(self, *args, **kwargs):\n",
    "    \"\"\"Adds ResetCovarianceCallback to model callbacks.\"\"\"\n",
    "    kwargs[\"callbacks\"] = list(kwargs.get(\"callbacks\", []))\n",
    "    kwargs[\"callbacks\"].append(ResetCovarianceCallback())\n",
    "    return super().fit(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9Lt8e3NQh1Wf"
   },
   "outputs": [],
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "W7B-EaEbh1ZF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "68/68 [==============================] - 1s 4ms/step - loss: 0.0658 - mean_squared_error: 0.0658 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
      "Epoch 2/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0294 - val_mean_squared_error: 0.0294\n",
      "Epoch 3/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.0250 - val_mean_squared_error: 0.0250\n",
      "Epoch 4/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "Epoch 5/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
      "Epoch 6/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 7/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
      "Epoch 8/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
      "Epoch 9/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
      "Epoch 10/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "Epoch 11/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0089 - val_mean_squared_error: 0.0089\n",
      "Epoch 12/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
      "Epoch 13/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
      "Epoch 14/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
      "Epoch 15/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
      "Epoch 16/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
      "Epoch 17/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "Epoch 18/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
      "Epoch 19/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0052 - mean_squared_error: 0.0051 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 20/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 21/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 22/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 23/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 24/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 25/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 26/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 27/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 28/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 29/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 30/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 31/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 32/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 33/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 34/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0024\n",
      "Epoch 35/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 36/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 37/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 38/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 39/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 40/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 41/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 42/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 43/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 44/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 45/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 46/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0024 - mean_squared_error: 0.0023 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 47/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0020 - val_mean_squared_error: 0.0019\n",
      "Epoch 48/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 49/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 50/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0023 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 51/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 52/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 53/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 54/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 55/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 56/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 57/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 58/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 59/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 60/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 61/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 62/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 63/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 64/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 65/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0016\n",
      "Epoch 66/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 67/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 68/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 69/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 70/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 71/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 72/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 73/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 74/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0015\n",
      "Epoch 75/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 76/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0015\n",
      "Epoch 77/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 78/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 79/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 80/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0017 - val_mean_squared_error: 0.0016\n",
      "Epoch 81/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 82/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 83/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 84/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 85/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 86/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 87/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 88/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 89/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 90/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0016 - val_mean_squared_error: 0.0015\n",
      "Epoch 91/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 92/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 93/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 0.0014\n",
      "Epoch 94/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0016 - val_mean_squared_error: 0.0015\n",
      "Epoch 95/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 96/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 97/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 98/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 99/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 100/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 101/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 102/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 103/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 104/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0018 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 105/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 106/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 107/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 108/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 109/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0017 - val_mean_squared_error: 0.0016\n",
      "Epoch 110/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 111/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 112/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0014\n",
      "Epoch 113/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 114/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 115/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 116/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 117/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 118/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 119/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 120/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 121/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 122/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 123/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 124/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0013\n",
      "Epoch 125/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0016 - val_mean_squared_error: 0.0015\n",
      "Epoch 126/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 127/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 128/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 129/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 130/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 131/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 132/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 133/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 134/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 0.0014 - val_mean_squared_error: 0.0013\n",
      "Epoch 135/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 136/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 137/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0015 - val_mean_squared_error: 0.0014\n",
      "Epoch 138/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 139/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 140/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 141/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 142/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 143/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 144/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0014 - val_mean_squared_error: 0.0013\n",
      "Epoch 145/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 146/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 147/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 148/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 149/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 150/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0017 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 151/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 152/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 153/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 154/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 155/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 156/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 157/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 158/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 159/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 160/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 161/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 162/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 163/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 164/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 165/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 166/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 167/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 168/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 169/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 170/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 171/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0016 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 172/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 173/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 174/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 175/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 176/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 177/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 178/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 179/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 180/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 181/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 182/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 183/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 184/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 185/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 186/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 187/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 188/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 189/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 190/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 191/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 192/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 193/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 194/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 195/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 196/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 197/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 198/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 199/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 200/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 201/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0016 - val_mean_squared_error: 0.0015\n",
      "Epoch 202/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 203/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 204/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 205/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 206/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 207/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 208/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 209/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 210/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 211/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 212/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 213/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 214/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 215/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 216/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 217/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 218/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 219/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 220/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 221/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 222/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 223/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 224/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 225/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 226/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 227/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 228/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 229/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 230/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 231/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 232/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 233/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 234/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 235/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 236/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 237/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 238/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 239/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0014 - val_mean_squared_error: 0.0013\n",
      "Epoch 240/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 241/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 242/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 243/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 244/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 245/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 246/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 247/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 248/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 249/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 250/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 251/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 252/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 253/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 254/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 255/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0014 - val_mean_squared_error: 0.0013\n",
      "Epoch 256/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 257/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 258/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 259/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 260/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 261/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 262/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 263/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 264/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 265/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 266/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 267/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0014 - val_mean_squared_error: 0.0013\n",
      "Epoch 268/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 269/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 270/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 271/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 272/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 273/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 274/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 275/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 276/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 277/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 278/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 279/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 280/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 281/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 282/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 283/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 284/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 285/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 286/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 287/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 288/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 289/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0015 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 290/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 291/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 292/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 293/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 294/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 295/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 296/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 297/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 298/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 299/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 300/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 301/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 302/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 303/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 304/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 305/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 306/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 307/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 308/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 309/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 310/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 311/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 312/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 313/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 314/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 315/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 316/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 317/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 318/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 319/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 320/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 321/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 322/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 323/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 324/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 325/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 326/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 327/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 328/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 329/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 330/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 331/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 332/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 333/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 334/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 335/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 336/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 337/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 338/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 339/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 340/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 341/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 342/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 343/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 344/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 345/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 346/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 347/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 348/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 349/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 350/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 351/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 352/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 353/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 354/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 355/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 356/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 357/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 358/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 359/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 360/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 361/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 362/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 363/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 364/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 365/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 366/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 367/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 368/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 369/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 370/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 371/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 372/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 373/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 374/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 375/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 376/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 377/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 378/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 379/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 380/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 381/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 382/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 383/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 384/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 385/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 386/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 387/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 388/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 389/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 390/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 391/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 392/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 393/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 394/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 395/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 396/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 397/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 398/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 399/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 400/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 401/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 402/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 403/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 404/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 405/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 406/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 407/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 408/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 409/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 410/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 411/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 412/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 413/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 414/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 415/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 416/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 417/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 418/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 419/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 420/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 421/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 422/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 423/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 424/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 425/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 426/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 427/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 428/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 429/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 430/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 431/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 432/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 433/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 434/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 435/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 436/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 437/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 438/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 439/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 440/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 441/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 442/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 443/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 444/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 445/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 446/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 447/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 448/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 449/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 450/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 451/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 452/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 453/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 454/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 455/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 456/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 457/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 458/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 459/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 460/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 461/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 462/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 463/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 464/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 465/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 466/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 467/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 468/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 469/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 470/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 471/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 472/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 473/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 474/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 475/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 476/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 477/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 478/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 479/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 480/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 481/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 482/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 483/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 484/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 485/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 486/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 487/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 488/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 489/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 490/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 491/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 492/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 493/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 494/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 495/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 496/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 497/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 498/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 499/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 500/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 501/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 502/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 503/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 504/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 505/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 506/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 507/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 508/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 509/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 510/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 511/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 512/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 513/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 514/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 515/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 516/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 517/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 518/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 519/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 520/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 521/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 522/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 523/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 524/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 525/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 526/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 527/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 528/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 529/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 530/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 531/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 532/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 533/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 534/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 535/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 536/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 537/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 538/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 539/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 540/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 541/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 542/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 543/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 544/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 545/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0012\n",
      "Epoch 546/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 547/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 548/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 549/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 550/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 551/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 552/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 553/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 554/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 555/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 556/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 557/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 558/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 559/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 560/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 561/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 562/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 563/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0010 - val_mean_squared_error: 9.9776e-04\n",
      "Epoch 564/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 565/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 566/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 567/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 568/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 569/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 570/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 571/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 572/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 573/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 574/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 575/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 576/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 577/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0010 - val_mean_squared_error: 9.9317e-04\n",
      "Epoch 578/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 579/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 580/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 581/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 582/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 583/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 584/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 585/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 586/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 587/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 588/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 589/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 590/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 591/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 592/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 593/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 594/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 595/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 596/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 597/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 598/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 599/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 600/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 601/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 602/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 603/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 604/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 605/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 606/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 607/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 608/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 609/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 610/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 611/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 612/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 613/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 614/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 615/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 616/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 617/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 618/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 619/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 620/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 621/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 622/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 623/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 624/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 625/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 626/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 627/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 628/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 629/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 630/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 631/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 632/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 633/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 634/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 635/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 636/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 637/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 638/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 639/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 640/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 641/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 642/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 643/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n",
      "Epoch 644/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 645/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 646/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0014 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 647/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 648/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 649/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 650/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 651/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 652/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 653/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 654/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 655/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 656/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 657/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 658/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 659/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 660/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 661/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 662/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 663/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 664/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 665/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 666/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 667/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 668/1000\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 669/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 670/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 671/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 672/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 673/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 674/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 675/1000\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 676/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0010\n",
      "Epoch 677/1000\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0011\n"
     ]
    }
   ],
   "source": [
    "# fit_config = dict( batch_size= 64,  epochs= 1000,\n",
    "#                 validation_data = (X_val, y_val),\n",
    "#                 callbacks=[callback] ) # batch_size= 512\n",
    "\n",
    "sngp_model = DeepResNetSNGPWithCovReset(**resnet_config)\n",
    "sngp_model.compile(**train_config)\n",
    "history = sngp_model.fit(X_train, y_train, **fit_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XALS5jsoM-7O"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "g4JqFioZvRsx"
   },
   "outputs": [],
   "source": [
    "# # This mean-field method is implemented as a built-in function layers.gaussian_process.mean_field_logits:\n",
    "\n",
    "# def compute_posterior_mean_probability(logits, covmat, lambda_param=np.pi / 8.):\n",
    "#   # Computes uncertainty-adjusted logits using the built-in method.\n",
    "#   logits_adjusted = nlp_layers.gaussian_process.mean_field_logits(\n",
    "#       logits, covmat, mean_field_factor=lambda_param)\n",
    "\n",
    "#   return logits_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hNtkNt2RKiXM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "iIgSEdpYKiXM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean variance -- 0.0017394731985405087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean variance -- 0.001767933601513505\n",
      "mean variance -- 0.003516973927617073\n",
      "mean variance -- 0.36574944853782654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 22:34:57.108406: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x55dfb241c560\n"
     ]
    }
   ],
   "source": [
    "def compute_variance(x):\n",
    "  hidden, sngp_logits, sngp_covmat = sngp_model(x, return_covmat=True)\n",
    "\n",
    "  sngp_variance = tf.linalg.diag_part(sngp_covmat)[:, None]\n",
    "\n",
    "  mean_var = np.mean(sngp_variance)\n",
    "  print(f'mean variance -- {mean_var}')\n",
    "\n",
    "  # print(hidden.shape)\n",
    "  # print(sngp_variance)\n",
    "  return hidden, sngp_variance\n",
    "\n",
    "train_hidden_sngp, train_var_sngp = compute_variance(X_train)\n",
    "test_hidden_sngp, test_var_sngp = compute_variance(X_test)\n",
    "shift_hidden_sngp, shift_var_sngp = compute_variance(X_shift)\n",
    "OOD_hidden_sngp, OOD_var_sngp = compute_variance(OOD)\n",
    "\n",
    "\n",
    "#train_var_sngp = train_var_sngp.numpy().ravel()\n",
    "test_var_sngp = test_var_sngp.numpy().ravel()\n",
    "shift_var_sngp = shift_var_sngp.numpy().ravel()\n",
    "OOD_var_sngp = OOD_var_sngp.numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Yu23sCXdKiXM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse -- 0.0012698224512589058\n",
      "mse -- 0.002262419121307845\n"
     ]
    }
   ],
   "source": [
    "def compute_mse(model, X, y):\n",
    "  hidden, sngp_logits, sngp_covmat = model(X, return_covmat=True)\n",
    "  # preds = compute_posterior_mean_probability(sngp_logits, sngp_covmat)\n",
    "  mse = mean_squared_error(y, sngp_logits)\n",
    "  print(f'mse -- {mse}')\n",
    "  return\n",
    "compute_mse(sngp_model, X_test, y_test)\n",
    "compute_mse(sngp_model, X_shift, y_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "SmTkDc2dKiXN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gmdx2gHmKiXN"
   },
   "outputs": [],
   "source": [
    "# Compute distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fEUxlA8I3zEv"
   },
   "outputs": [],
   "source": [
    "def compute_distane(train_hidden, test_hidden, k = 10):\n",
    "    distances = tf.norm(tf.expand_dims(test_hidden, axis=1) - tf.expand_dims(train_hidden, axis=0), axis=-1)\n",
    "    topk_distances, topk_indices = tf.math.top_k(-distances, k=k)  # Use negative distances for smallest k distances\n",
    "    return - topk_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wpr2C1_yKiXN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 22:53:08.403444: W external/local_tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 435.06MiB (rounded to 456192000)requested by op Sub\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-12-12 22:53:08.403459: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-12-12 22:53:08.403463: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 100, Chunks in use: 95. 25.0KiB allocated for chunks. 23.8KiB in use in bin. 438B client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403466: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 30, Chunks in use: 29. 16.0KiB allocated for chunks. 15.5KiB in use in bin. 14.5KiB client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403468: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403470: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 2, Chunks in use: 0. 4.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403472: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 7, Chunks in use: 6. 37.5KiB allocated for chunks. 33.5KiB in use in bin. 27.0KiB client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403474: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403476: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 3, Chunks in use: 1. 60.2KiB allocated for chunks. 17.0KiB in use in bin. 16.9KiB client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403477: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403479: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 19, Chunks in use: 19. 1.31MiB allocated for chunks. 1.31MiB in use in bin. 1.23MiB client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403481: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 1, Chunks in use: 0. 146.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403485: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 3, Chunks in use: 2. 1.10MiB allocated for chunks. 808.0KiB in use in bin. 624.2KiB client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403487: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 2, Chunks in use: 2. 1.12MiB allocated for chunks. 1.12MiB in use in bin. 1.09MiB client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403489: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403508: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 4, Chunks in use: 2. 10.78MiB allocated for chunks. 5.04MiB in use in bin. 5.04MiB client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403510: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 2. 8.00MiB allocated for chunks. 8.00MiB in use in bin. 8.00MiB client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403511: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403513: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403516: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403518: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403519: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403522: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 1. 847.46MiB allocated for chunks. 435.06MiB in use in bin. 435.06MiB client-requested in use in bin.\n",
      "2023-12-12 22:53:08.403524: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 435.06MiB was 256.00MiB, Chunk State: \n",
      "2023-12-12 22:53:08.403527: I external/local_tsl/tsl/framework/bfc_allocator.cc:1068]   Size: 412.41MiB | Requested Size: 23.4KiB | in_use: 0 | bin_num: 20, prev:   Size: 435.06MiB | Requested Size: 435.06MiB | in_use: 1 | bin_num: -1\n",
      "2023-12-12 22:53:08.403529: I external/local_tsl/tsl/framework/bfc_allocator.cc:1075] Next region of size 912326656\n",
      "2023-12-12 22:53:08.403531: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc000000 of size 256 next 1\n",
      "2023-12-12 22:53:08.403533: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc000100 of size 1280 next 2\n",
      "2023-12-12 22:53:08.403535: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc000600 of size 256 next 3\n",
      "2023-12-12 22:53:08.403537: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc000700 of size 256 next 4\n",
      "2023-12-12 22:53:08.403538: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc000800 of size 256 next 6\n",
      "2023-12-12 22:53:08.403540: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc000900 of size 512 next 7\n",
      "2023-12-12 22:53:08.403541: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc000b00 of size 256 next 5\n",
      "2023-12-12 22:53:08.403542: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc000c00 of size 256 next 8\n",
      "2023-12-12 22:53:08.403544: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc000d00 of size 512 next 13\n",
      "2023-12-12 22:53:08.403545: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc000f00 of size 512 next 16\n",
      "2023-12-12 22:53:08.403546: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001100 of size 512 next 18\n",
      "2023-12-12 22:53:08.403547: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001300 of size 256 next 11\n",
      "2023-12-12 22:53:08.403549: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001400 of size 256 next 12\n",
      "2023-12-12 22:53:08.403550: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001500 of size 256 next 21\n",
      "2023-12-12 22:53:08.403551: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001600 of size 256 next 22\n",
      "2023-12-12 22:53:08.403553: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001700 of size 256 next 20\n",
      "2023-12-12 22:53:08.403554: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001800 of size 256 next 23\n",
      "2023-12-12 22:53:08.403555: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001900 of size 256 next 26\n",
      "2023-12-12 22:53:08.403556: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001a00 of size 256 next 27\n",
      "2023-12-12 22:53:08.403558: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001b00 of size 256 next 24\n",
      "2023-12-12 22:53:08.403559: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001c00 of size 256 next 102\n",
      "2023-12-12 22:53:08.403561: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001d00 of size 256 next 25\n",
      "2023-12-12 22:53:08.403562: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001e00 of size 256 next 30\n",
      "2023-12-12 22:53:08.403563: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc001f00 of size 256 next 31\n",
      "2023-12-12 22:53:08.403565: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc002000 of size 256 next 32\n",
      "2023-12-12 22:53:08.403566: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc002100 of size 256 next 33\n",
      "2023-12-12 22:53:08.403567: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc002200 of size 256 next 34\n",
      "2023-12-12 22:53:08.403568: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc002300 of size 256 next 35\n",
      "2023-12-12 22:53:08.403570: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc002400 of size 256 next 36\n",
      "2023-12-12 22:53:08.403571: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc002500 of size 256 next 37\n",
      "2023-12-12 22:53:08.403572: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc002600 of size 256 next 38\n",
      "2023-12-12 22:53:08.403574: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc002700 of size 256 next 39\n",
      "2023-12-12 22:53:08.403575: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc002800 of size 256 next 40\n",
      "2023-12-12 22:53:08.403576: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc002900 of size 512 next 41\n",
      "2023-12-12 22:53:08.403577: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc002b00 of size 512 next 43\n",
      "2023-12-12 22:53:08.403579: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc002d00 of size 512 next 45\n",
      "2023-12-12 22:53:08.403580: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc002f00 of size 512 next 46\n",
      "2023-12-12 22:53:08.403581: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc003100 of size 256 next 47\n",
      "2023-12-12 22:53:08.403582: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc003200 of size 512 next 49\n",
      "2023-12-12 22:53:08.403584: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc003400 of size 768 next 9\n",
      "2023-12-12 22:53:08.403585: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc003700 of size 23040 next 29\n",
      "2023-12-12 22:53:08.403587: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc009100 of size 113664 next 15\n",
      "2023-12-12 22:53:08.403588: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc024d00 of size 65536 next 14\n",
      "2023-12-12 22:53:08.403590: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc034d00 of size 65536 next 17\n",
      "2023-12-12 22:53:08.403591: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc044d00 of size 105728 next 197\n",
      "2023-12-12 22:53:08.403592: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc05ea00 of size 150016 next 28\n",
      "2023-12-12 22:53:08.403594: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc083400 of size 65536 next 42\n",
      "2023-12-12 22:53:08.403595: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc093400 of size 65536 next 44\n",
      "2023-12-12 22:53:08.403596: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0a3400 of size 65536 next 48\n",
      "2023-12-12 22:53:08.403598: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0b3400 of size 65536 next 50\n",
      "2023-12-12 22:53:08.403599: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0c3400 of size 65536 next 51\n",
      "2023-12-12 22:53:08.403601: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d3400 of size 512 next 52\n",
      "2023-12-12 22:53:08.403602: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d3600 of size 512 next 53\n",
      "2023-12-12 22:53:08.403603: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d3800 of size 256 next 54\n",
      "2023-12-12 22:53:08.403605: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d3900 of size 256 next 93\n",
      "2023-12-12 22:53:08.403606: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d3a00 of size 256 next 105\n",
      "2023-12-12 22:53:08.403607: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d3b00 of size 256 next 57\n",
      "2023-12-12 22:53:08.403609: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d3c00 of size 256 next 58\n",
      "2023-12-12 22:53:08.403610: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d3d00 of size 256 next 59\n",
      "2023-12-12 22:53:08.403611: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d3e00 of size 256 next 60\n",
      "2023-12-12 22:53:08.403612: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d3f00 of size 256 next 61\n",
      "2023-12-12 22:53:08.403614: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4000 of size 256 next 62\n",
      "2023-12-12 22:53:08.403615: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4100 of size 256 next 63\n",
      "2023-12-12 22:53:08.403616: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4200 of size 256 next 64\n",
      "2023-12-12 22:53:08.403618: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4300 of size 256 next 65\n",
      "2023-12-12 22:53:08.403619: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4400 of size 256 next 66\n",
      "2023-12-12 22:53:08.403620: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4500 of size 256 next 67\n",
      "2023-12-12 22:53:08.403622: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4600 of size 256 next 68\n",
      "2023-12-12 22:53:08.403623: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4700 of size 256 next 76\n",
      "2023-12-12 22:53:08.403624: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4800 of size 256 next 77\n",
      "2023-12-12 22:53:08.403625: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4900 of size 256 next 88\n",
      "2023-12-12 22:53:08.403627: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4a00 of size 256 next 70\n",
      "2023-12-12 22:53:08.403628: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4b00 of size 256 next 97\n",
      "2023-12-12 22:53:08.403630: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4c00 of size 256 next 91\n",
      "2023-12-12 22:53:08.403631: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4d00 of size 256 next 83\n",
      "2023-12-12 22:53:08.403632: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4e00 of size 256 next 19\n",
      "2023-12-12 22:53:08.403634: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d4f00 of size 256 next 206\n",
      "2023-12-12 22:53:08.403637: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d5000 of size 256 next 106\n",
      "2023-12-12 22:53:08.403638: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d5100 of size 256 next 109\n",
      "2023-12-12 22:53:08.403639: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d5200 of size 256 next 84\n",
      "2023-12-12 22:53:08.403641: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d5300 of size 256 next 56\n",
      "2023-12-12 22:53:08.403642: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d5400 of size 512 next 114\n",
      "2023-12-12 22:53:08.403643: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d5600 of size 256 next 150\n",
      "2023-12-12 22:53:08.403645: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc0d5700 of size 256 next 104\n",
      "2023-12-12 22:53:08.403646: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d5800 of size 256 next 89\n",
      "2023-12-12 22:53:08.403647: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d5900 of size 256 next 221\n",
      "2023-12-12 22:53:08.403648: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d5a00 of size 256 next 239\n",
      "2023-12-12 22:53:08.403650: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc0d5b00 of size 256 next 231\n",
      "2023-12-12 22:53:08.403651: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d5c00 of size 256 next 123\n",
      "2023-12-12 22:53:08.403652: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d5d00 of size 512 next 111\n",
      "2023-12-12 22:53:08.403654: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d5f00 of size 768 next 134\n",
      "2023-12-12 22:53:08.403655: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc0d6200 of size 256 next 230\n",
      "2023-12-12 22:53:08.403656: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d6300 of size 256 next 138\n",
      "2023-12-12 22:53:08.403658: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d6400 of size 512 next 110\n",
      "2023-12-12 22:53:08.403659: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d6600 of size 7936 next 456\n",
      "2023-12-12 22:53:08.403660: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d8500 of size 6656 next 463\n",
      "2023-12-12 22:53:08.403662: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0d9f00 of size 256 next 462\n",
      "2023-12-12 22:53:08.403663: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0da000 of size 256 next 157\n",
      "2023-12-12 22:53:08.403664: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0da100 of size 768 next 162\n",
      "2023-12-12 22:53:08.403666: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0da400 of size 512 next 158\n",
      "2023-12-12 22:53:08.403667: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0da600 of size 256 next 86\n",
      "2023-12-12 22:53:08.403668: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0da700 of size 256 next 155\n",
      "2023-12-12 22:53:08.403670: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0da800 of size 768 next 55\n",
      "2023-12-12 22:53:08.403671: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0dab00 of size 512 next 101\n",
      "2023-12-12 22:53:08.403672: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0dad00 of size 256 next 113\n",
      "2023-12-12 22:53:08.403673: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0dae00 of size 512 next 69\n",
      "2023-12-12 22:53:08.403675: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0db000 of size 256 next 108\n",
      "2023-12-12 22:53:08.403676: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0db100 of size 256 next 94\n",
      "2023-12-12 22:53:08.403677: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0db200 of size 256 next 92\n",
      "2023-12-12 22:53:08.403679: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0db300 of size 256 next 95\n",
      "2023-12-12 22:53:08.403680: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0db400 of size 5632 next 116\n",
      "2023-12-12 22:53:08.403686: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0dca00 of size 65536 next 117\n",
      "2023-12-12 22:53:08.403688: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc0eca00 of size 2048 next 207\n",
      "2023-12-12 22:53:08.403689: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0ed200 of size 512 next 254\n",
      "2023-12-12 22:53:08.403691: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc0ed400 of size 2048 next 146\n",
      "2023-12-12 22:53:08.403692: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0edc00 of size 512 next 219\n",
      "2023-12-12 22:53:08.403693: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0ede00 of size 512 next 215\n",
      "2023-12-12 22:53:08.403695: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc0ee000 of size 256 next 192\n",
      "2023-12-12 22:53:08.403696: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc0ee100 of size 83968 next 191\n",
      "2023-12-12 22:53:08.403697: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc102900 of size 21248 next 195\n",
      "2023-12-12 22:53:08.403699: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc107c00 of size 85504 next 127\n",
      "2023-12-12 22:53:08.403700: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc11ca00 of size 4096 next 140\n",
      "2023-12-12 22:53:08.403701: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc11da00 of size 4096 next 75\n",
      "2023-12-12 22:53:08.403703: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc11ea00 of size 65536 next 154\n",
      "2023-12-12 22:53:08.403704: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc12ea00 of size 65536 next 79\n",
      "2023-12-12 22:53:08.403705: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc13ea00 of size 65536 next 103\n",
      "2023-12-12 22:53:08.403707: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc14ea00 of size 65536 next 98\n",
      "2023-12-12 22:53:08.403708: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc15ea00 of size 512 next 73\n",
      "2023-12-12 22:53:08.403709: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc15ec00 of size 65536 next 122\n",
      "2023-12-12 22:53:08.403711: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc16ec00 of size 512 next 124\n",
      "2023-12-12 22:53:08.403712: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc16ee00 of size 65536 next 128\n",
      "2023-12-12 22:53:08.403713: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc17ee00 of size 512 next 132\n",
      "2023-12-12 22:53:08.403714: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc17f000 of size 4096 next 137\n",
      "2023-12-12 22:53:08.403716: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180000 of size 256 next 141\n",
      "2023-12-12 22:53:08.403717: I external/local_tsl/tsl/framework/bfc_alloca"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Sub] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb Cell 31\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B158.132.205.96/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mTF_GPU_ALLOCATOR\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda_malloc_async\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B158.132.205.96/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m test_distance \u001b[39m=\u001b[39m compute_distane(X_train, X_test)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B158.132.205.96/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m shift_distance \u001b[39m=\u001b[39m compute_distane(X_train, X_shift)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B158.132.205.96/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m OOD_distance \u001b[39m=\u001b[39m compute_distane(X_train, OOD)\n",
      "\u001b[1;32m/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb Cell 31\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B158.132.205.96/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_distane\u001b[39m(train_hidden, test_hidden, k \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B158.132.205.96/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     distances \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnorm(tf\u001b[39m.\u001b[39;49mexpand_dims(test_hidden, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m-\u001b[39;49m tf\u001b[39m.\u001b[39;49mexpand_dims(train_hidden, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m), axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B158.132.205.96/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     topk_distances, topk_indices \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mtop_k(\u001b[39m-\u001b[39mdistances, k\u001b[39m=\u001b[39mk)  \u001b[39m# Use negative distances for smallest k distances\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B158.132.205.96/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m topk_distances\n",
      "File \u001b[0;32m~/anaconda3/envs/xue_long_tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/xue_long_tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Sub] name: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tor.cc:1095] InUse at 7f29dc180100 of size 256 next 144\n",
      "2023-12-12 22:53:08.403718: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180200 of size 256 next 149\n",
      "2023-12-12 22:53:08.403720: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180300 of size 256 next 151\n",
      "2023-12-12 22:53:08.403721: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180400 of size 256 next 159\n",
      "2023-12-12 22:53:08.403722: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180500 of size 256 next 163\n",
      "2023-12-12 22:53:08.403723: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180600 of size 256 next 165\n",
      "2023-12-12 22:53:08.403725: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180700 of size 256 next 167\n",
      "2023-12-12 22:53:08.403726: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180800 of size 256 next 168\n",
      "2023-12-12 22:53:08.403727: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180900 of size 256 next 170\n",
      "2023-12-12 22:53:08.403729: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180a00 of size 256 next 171\n",
      "2023-12-12 22:53:08.403730: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180b00 of size 256 next 173\n",
      "2023-12-12 22:53:08.403732: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180c00 of size 256 next 175\n",
      "2023-12-12 22:53:08.403733: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180d00 of size 256 next 177\n",
      "2023-12-12 22:53:08.403734: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180e00 of size 256 next 179\n",
      "2023-12-12 22:53:08.403736: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc180f00 of size 256 next 180\n",
      "2023-12-12 22:53:08.403737: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc181000 of size 256 next 182\n",
      "2023-12-12 22:53:08.403738: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc181100 of size 256 next 183\n",
      "2023-12-12 22:53:08.403739: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc181200 of size 256 next 185\n",
      "2023-12-12 22:53:08.403741: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc181300 of size 256 next 187\n",
      "2023-12-12 22:53:08.403742: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc181400 of size 256 next 252\n",
      "2023-12-12 22:53:08.403743: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc181500 of size 256 next 227\n",
      "2023-12-12 22:53:08.403745: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc181600 of size 256 next 209\n",
      "2023-12-12 22:53:08.403746: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc181700 of size 256 next 211\n",
      "2023-12-12 22:53:08.403747: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc181800 of size 5888 next 264\n",
      "2023-12-12 22:53:08.403749: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc182f00 of size 512 next 243\n",
      "2023-12-12 22:53:08.403750: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc183100 of size 512 next 112\n",
      "2023-12-12 22:53:08.403751: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc183300 of size 512 next 240\n",
      "2023-12-12 22:53:08.403752: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc183500 of size 67328 next 261\n",
      "2023-12-12 22:53:08.403754: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc193c00 of size 560640 next 459\n",
      "2023-12-12 22:53:08.403755: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc21ca00 of size 325888 next 457\n",
      "2023-12-12 22:53:08.403757: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc26c300 of size 447232 next 249\n",
      "2023-12-12 22:53:08.403758: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc2d9600 of size 614400 next 189\n",
      "2023-12-12 22:53:08.403760: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dc36f600 of size 3331072 next 143\n",
      "2023-12-12 22:53:08.403762: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dc69ca00 of size 4194304 next 131\n",
      "2023-12-12 22:53:08.403763: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dca9ca00 of size 4194304 next 242\n",
      "2023-12-12 22:53:08.403764: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dce9ca00 of size 2211840 next 458\n",
      "2023-12-12 22:53:08.403766: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dd0b8a00 of size 17408 next 71\n",
      "2023-12-12 22:53:08.403767: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dd0bce00 of size 380160 next 245\n",
      "2023-12-12 22:53:08.403768: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29dd119b00 of size 2691840 next 203\n",
      "2023-12-12 22:53:08.403770: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dd3aae00 of size 3072000 next 216\n",
      "2023-12-12 22:53:08.403771: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 7f29dd698e00 of size 456192000 next 199\n",
      "2023-12-12 22:53:08.403773: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 7f29f89a7e00 of size 432439808 next 18446744073709551615\n",
      "2023-12-12 22:53:08.403775: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-12-12 22:53:08.403778: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 95 Chunks of size 256 totalling 23.8KiB\n",
      "2023-12-12 22:53:08.403779: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 25 Chunks of size 512 totalling 12.5KiB\n",
      "2023-12-12 22:53:08.403781: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 768 totalling 3.0KiB\n",
      "2023-12-12 22:53:08.403782: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-12-12 22:53:08.403784: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 4096 totalling 8.0KiB\n",
      "2023-12-12 22:53:08.403785: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 5632 totalling 5.5KiB\n",
      "2023-12-12 22:53:08.403787: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 5888 totalling 5.8KiB\n",
      "2023-12-12 22:53:08.403788: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6656 totalling 6.5KiB\n",
      "2023-12-12 22:53:08.403790: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 7936 totalling 7.8KiB\n",
      "2023-12-12 22:53:08.403791: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 17408 totalling 17.0KiB\n",
      "2023-12-12 22:53:08.403793: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 14 Chunks of size 65536 totalling 896.0KiB\n",
      "2023-12-12 22:53:08.403794: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 67328 totalling 65.8KiB\n",
      "2023-12-12 22:53:08.403796: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 83968 totalling 82.0KiB\n",
      "2023-12-12 22:53:08.403797: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 85504 totalling 83.5KiB\n",
      "2023-12-12 22:53:08.403799: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 105728 totalling 103.2KiB\n",
      "2023-12-12 22:53:08.403801: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 113664 totalling 111.0KiB\n",
      "2023-12-12 22:53:08.403802: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 380160 totalling 371.2KiB\n",
      "2023-12-12 22:53:08.403804: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 447232 totalling 436.8KiB\n",
      "2023-12-12 22:53:08.403805: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 560640 totalling 547.5KiB\n",
      "2023-12-12 22:53:08.403807: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 614400 totalling 600.0KiB\n",
      "2023-12-12 22:53:08.403808: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2211840 totalling 2.11MiB\n",
      "2023-12-12 22:53:08.403810: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3072000 totalling 2.93MiB\n",
      "2023-12-12 22:53:08.403811: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 4194304 totalling 8.00MiB\n",
      "2023-12-12 22:53:08.403813: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 456192000 totalling 435.06MiB\n",
      "2023-12-12 22:53:08.403814: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 451.41MiB\n",
      "2023-12-12 22:53:08.403816: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 912326656 memory_limit_: 912326656 available bytes: 0 curr_region_allocation_bytes_: 1824653312\n",
      "2023-12-12 22:53:08.403820: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       912326656\n",
      "InUse:                       473333760\n",
      "MaxInUse:                    473635840\n",
      "NumAllocs:                     6392708\n",
      "MaxAllocSize:                456192000\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-12-12 22:53:08.403824: W external/local_tsl/tsl/framework/bfc_allocator.cc:497] *****************************************************_______________________________________________\n",
      "2023-12-12 22:53:08.403835: W tensorflow/core/framework/op_kernel.cc:1827] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "           \n",
    "test_distance = compute_distane(X_train, X_test)\n",
    "shift_distance = compute_distane(X_train, X_shift)\n",
    "OOD_distance = compute_distane(X_train, OOD)\n",
    "\n",
    "# Compute mean along axis = 1 (rows)\n",
    "test_mean_inp = tf.reduce_mean(test_distance, axis=1).numpy()\n",
    "shift_mean_inp = tf.reduce_mean(shift_distance, axis=1).numpy()\n",
    "OOD_mean_inp = tf.reduce_mean(OOD_distance, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Efec1gzRKiXN"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_mean_inp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B158.132.205.96/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     ax\u001b[39m.\u001b[39mlegend()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B158.132.205.96/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     plt\u001b[39m.\u001b[39mxscale(\u001b[39m\"\u001b[39m\u001b[39mlog\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B158.132.205.96/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m plot_hidden_distance(ax, test_mean_inp,  label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mNormal\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# density=True,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B158.132.205.96/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m plot_hidden_distance(ax, shift_mean_inp,  label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mShift\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B158.132.205.96/home/user/xue_long/Resgression/Resgression/SNGP_Regression.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m plot_hidden_distance(ax, OOD_mean_inp,  label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mOOD\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_mean_inp' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"white\", font_scale = 1.5 )\n",
    "fig, ax = plt.subplots(figsize=(10, 6), layout='constrained')  #\n",
    "#ax.set_xscale('log', base=2)\n",
    "\n",
    "def plot_hidden_distance(ax, distance, label):\n",
    "    ax.hist(distance, bins= 20, alpha= 0.5,  label = label)\n",
    "    #ax.set_xscale('log', base=10)\n",
    "\n",
    "    ax.legend()\n",
    "    plt.xscale(\"log\")\n",
    "\n",
    "plot_hidden_distance(ax, test_mean_inp,  label = 'Normal') # density=True,\n",
    "plot_hidden_distance(ax, shift_mean_inp,  label = 'Shift')\n",
    "plot_hidden_distance(ax, OOD_mean_inp,  label = 'OOD')\n",
    "plt.xlabel('Input distance')\n",
    "\n",
    "plt.savefig('Input_dist_hist_reg.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFGaVUoYKiXN"
   },
   "outputs": [],
   "source": [
    "test_distance_sngp = compute_distane(train_hidden_sngp, test_hidden_sngp)\n",
    "OOD_distance_sngp = compute_distane(train_hidden_sngp, OOD_hidden_sngp)\n",
    "shift_distance_sngp = np.zeros((shift_hidden_sngp.shape[0], 10))\n",
    "batches = int((shift_hidden_sngp.shape[0]/1000))\n",
    "for i in range(batches):\n",
    "    s = i*1000\n",
    "    t = (i+1)*1000\n",
    "    print (s, t)\n",
    "    tmp = compute_distane(train_hidden_sngp, shift_hidden_sngp[s:t, :])\n",
    "    shift_distance_sngp[s:t, :] = tmp\n",
    "\n",
    "# Compute mean along axis 1 (rows)\n",
    "test_mean_sngp = tf.reduce_mean(test_distance_sngp, axis=1).numpy()\n",
    "shift_mean_sngp = tf.reduce_mean(shift_distance_sngp, axis=1).numpy()\n",
    "OOD_mean_sngp = tf.reduce_mean(OOD_distance_sngp, axis=1).numpy()\n",
    "\n",
    "print(test_hidden_sngp.shape)\n",
    "print(shift_hidden_sngp.shape)\n",
    "print(OOD_hidden_sngp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K6I4U-xxKiXN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOK7ijCfKiXN"
   },
   "outputs": [],
   "source": [
    "def plot_hidden_distance_hist(test_mean_sngp , shift_mean_sngp, OOD_mean_sngp, name ):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), layout='constrained' )\n",
    "    ax.set_xscale('log', base=10)\n",
    "    plt.hist(test_mean_sngp,  bins = 20, alpha= 0.5,  label = 'Normal') #color = 'blue',color = 'orange',color = 'green',\n",
    "    plt.hist(shift_mean_sngp, bins = 20, alpha= 0.5,  label = 'Shift')\n",
    "    plt.hist((OOD_mean_sngp),   bins = 20, alpha= 0.5,  label = 'OOD')\n",
    "    plt.xlabel('Hidden distance')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{name}')\n",
    "    plt.show()\n",
    "plot_hidden_distance_hist(test_mean_sngp , shift_mean_sngp, OOD_mean_sngp,  'Hidden_Dist_Hist_SNGP_reg.pdf' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-eSA4A_qKiXO"
   },
   "outputs": [],
   "source": [
    "def scatter_var_dist(test_dist, shift_dist, OOD_dist,  test_var, shift_var, OOD_var, name):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), layout='constrained' )\n",
    "    ax.set_xscale('log', base=10)\n",
    "    plt.scatter(test_dist,  test_var,  alpha= 0.5,   label = 'Non-shift') #color = 'blue',color = 'orange',color = 'green',\n",
    "    plt.scatter(shift_dist, shift_var, alpha= 0.5, label = 'Shift')\n",
    "    plt.scatter(OOD_dist,  OOD_var,   alpha= 0.5, label = 'OOD')\n",
    "    plt.xlabel('Hidden distance')\n",
    "    plt.ylabel('Variance')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{name}')\n",
    "    plt.show()\n",
    "scatter_var_dist(test_mean_sngp, shift_mean_sngp, OOD_mean_sngp, test_var_sngp, shift_var_sngp, OOD_var_sngp, 'Dist_Var_SNGP_reg.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQv5QZhfKiXO"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6BcWmPaKiXT"
   },
   "outputs": [],
   "source": [
    "def plot_variance_hist(test_var_sngp, shift_var_sngp, OOD_var_sngp, name):\n",
    "    fig, ax = plt.subplots(figsize=(6, 4), layout='constrained' )\n",
    "    ax.set_xscale('log', base=10)\n",
    "    plt.hist(test_var_sngp,  bins = 20, alpha= 0.5,  label = 'Normal') #color = 'blue',color = 'orange',color = 'green',\n",
    "    plt.hist(shift_var_sngp, bins = 20, alpha= 0.5,  label = 'Shift')\n",
    "    plt.hist(OOD_var_sngp,   bins = 20, alpha= 0.5,  label = 'OOD')\n",
    "    plt.xlabel('Variance')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{name}')\n",
    "    plt.show()\n",
    "plot_variance_hist(test_var_sngp, shift_var_sngp, OOD_var_sngp, 'SNGP_Var_reg.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJPeiimu7B-m"
   },
   "outputs": [],
   "source": [
    "# MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRpnvN0lvb7d"
   },
   "outputs": [],
   "source": [
    "num_ensemble = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIu3D4iIvcGr"
   },
   "outputs": [],
   "source": [
    "def mc_dropout_sampling(test_examples):\n",
    "  # Enable dropout during inference.\n",
    "  return resnet_model(test_examples, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kW6QIn2nvDYJ"
   },
   "outputs": [],
   "source": [
    "# Monte Carlo dropout inference.\n",
    "\n",
    "def Compute_MC(model, X, y):\n",
    "\n",
    "\n",
    "  hidden = model(X)[0]\n",
    "  preds = [ model(X)[1] for _ in range(num_ensemble) ]\n",
    "\n",
    "  preds = np.hstack(preds)\n",
    "\n",
    "\n",
    "  #predictions = tf.(predictions, axis=0)\n",
    "\n",
    "  pred_mean = np.mean(preds, axis=1)\n",
    "\n",
    "  vars = np.var(preds, axis=1)\n",
    "\n",
    "  # # pred = pred_list.mean(axis = 1)\n",
    "  mse = mean_squared_error(pred_mean, y)\n",
    "\n",
    "  # # vars = [ np.var(i) for i in pred_list]\n",
    "  mean_ = np.mean(vars)\n",
    "\n",
    "  print(f'mse--{mse} vars--{mean_}')\n",
    "  return hidden, vars\n",
    "\n",
    "train_hidden_mc, var_mc = Compute_MC(mc_dropout_sampling, X_train, y_train)\n",
    "test_hidden_mc, test_var_mc = Compute_MC(mc_dropout_sampling, X_test, y_test)\n",
    "shift_hidden_mc, shift_var_mc = Compute_MC(mc_dropout_sampling, X_shift, y_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Po93x447KiXT"
   },
   "outputs": [],
   "source": [
    "# OOD\n",
    "def Compute_MC_OOD(model, X):\n",
    "  hidden = model(X)[0]\n",
    "\n",
    "  predictions = []\n",
    "  predictions.append([model(X)[1] for _ in range(num_ensemble)])\n",
    "\n",
    "  predictions = tf.concat(predictions, axis=0)\n",
    "\n",
    "  vars = tf.math.reduce_variance(predictions, axis=0)\n",
    "\n",
    "  mean_ = np.mean(vars)\n",
    "  print(f'vars--{mean_}')\n",
    "  return hidden, vars\n",
    "\n",
    "OOD_hidden_mc, OOD_var_mc = Compute_MC_OOD(mc_dropout_sampling, OOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjM7eIjRGPxN"
   },
   "outputs": [],
   "source": [
    "test_distance_mc = compute_distane(train_hidden_mc, test_hidden_mc)\n",
    "OOD_distance_mc = compute_distane(train_hidden_mc, OOD_hidden_mc)\n",
    "\n",
    "shift_distance_mc = np.zeros((shift_hidden_mc.shape[0], 10))\n",
    "batches = int((shift_hidden_mc.shape[0]/1000))\n",
    "for i in range(batches):\n",
    "    s = i*1000\n",
    "    t = (i+1)*1000\n",
    "    print (s, t)\n",
    "    tmp = compute_distane(train_hidden_sngp, shift_hidden_mc[s:t, :])\n",
    "    shift_distance_mc[s:t, :] = tmp\n",
    "\n",
    "\n",
    "\n",
    "# compute mean along axis 1 (rows)\n",
    "test_mean_mc = tf.reduce_mean(test_distance_mc, axis=1).numpy()\n",
    "shift_mean_mc = tf.reduce_mean(shift_distance_mc, axis=1).numpy()\n",
    "OOD_mean_mc = tf.reduce_mean(OOD_distance_mc, axis=1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aYWo6hxIANe9"
   },
   "outputs": [],
   "source": [
    "# Deep ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqG1z5Lou6wA"
   },
   "outputs": [],
   "source": [
    "resnet_ensemble = []\n",
    "for _ in range(num_ensemble):\n",
    "  resnet_model = DeepResNet(**resnet_config)\n",
    "  resnet_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "  resnet_model.fit(X_train, y_train, verbose=0, **fit_config)\n",
    "  resnet_ensemble.append(resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMbAjAzOKiXU"
   },
   "outputs": [],
   "source": [
    "def Compute_Deep(model_list, X, y):\n",
    "\n",
    "  hidden = [model(X)[0] for model in model_list]\n",
    "  hidden = tf.reduce_mean(hidden, axis = 0)\n",
    "\n",
    "  ensemble_predictions = np.array([model(X)[1] for model in model_list])\n",
    "\n",
    "  mean_prediction = np.mean(ensemble_predictions, axis=0)\n",
    "  vars = np.var(ensemble_predictions, axis=0)\n",
    "\n",
    "  mse = mean_squared_error(mean_prediction, y)\n",
    "  print(f'mse: {mse} -- Mean Variance:{np.mean(vars)}')\n",
    "  return hidden, vars\n",
    "\n",
    "train_hidden_deep, var = Compute_Deep(resnet_ensemble, X_train, y_train)\n",
    "test_hidden_deep, test_var_deep = Compute_Deep(resnet_ensemble, X_test, y_test)\n",
    "shift_hidden_deep, shift_var_deep = Compute_Deep(resnet_ensemble, X_shift, y_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KK34ULJHKiXU"
   },
   "outputs": [],
   "source": [
    "def Compute_Deep_OOD(model_list, X):\n",
    "  hidden = [ model(X)[0] for model in model_list]\n",
    "  hidden = tf.reduce_mean(hidden, axis = 0)\n",
    "\n",
    "  #print(ensemble_logit_samples)\n",
    "  # pred_list = np.hstack([model(X)[1] for model in model_list])\n",
    "  # vars = [ np.var(i) for i in pred_list]\n",
    "  # vars = [ np.var(i) for i in pred_list]\n",
    "\n",
    "  ensemble_predictions = np.array( [model(X)[1] for model in model_list])\n",
    "\n",
    "  mean_prediction = np.mean(ensemble_predictions, axis=0)\n",
    "  vars = np.var(ensemble_predictions, axis=0)\n",
    "\n",
    "  print(f'Mean Variance:{np.mean(vars)}')\n",
    "\n",
    "  return hidden, vars\n",
    "\n",
    "OOD_hidden_deep, OOD_var_deep = Compute_Deep_OOD(resnet_ensemble, OOD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vszA47ZSKiXU"
   },
   "outputs": [],
   "source": [
    "test_distance_deep = compute_distane(train_hidden_deep, test_hidden_deep)\n",
    "#shift_distance_deep = compute_distane(train_hidden_deep, shift_hidden_deep)\n",
    "OOD_distance_deep = compute_distane(train_hidden_deep, OOD_hidden_deep)\n",
    "\n",
    "shift_distance_deep = np.zeros((shift_hidden_deep.shape[0], 10))\n",
    "batches = int((shift_hidden_deep.shape[0]/1000))\n",
    "for i in range(batches):\n",
    "    s = i*1000\n",
    "    t = (i+1)*1000\n",
    "    print (s, t)\n",
    "    tmp = compute_distane(train_hidden_sngp, shift_hidden_deep[s:t, :])\n",
    "    shift_distance_deep[s:t, :] = tmp\n",
    "\n",
    "# compute mean along axis 1 (rows)\n",
    "test_mean_deep = tf.reduce_mean(test_distance_deep, axis=1).numpy()\n",
    "shift_mean_deep = tf.reduce_mean(shift_distance_deep, axis=1).numpy()\n",
    "OOD_mean_deep = tf.reduce_mean(OOD_distance_deep, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-baBWReAW17"
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", font_scale = 1.5)\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(16, 4.5), layout='constrained' ) # 11.69,8.27\n",
    "\n",
    "ax1.hist(test_mean_inp, bins = 20, alpha= 0.6, label = 'Normal') # density=True,\n",
    "ax1.hist(shift_mean_inp, bins = 20, alpha= 0.6, label = 'Shift')\n",
    "ax1.hist(OOD_mean_inp, alpha= 0.6, label = 'OOD')\n",
    "ax1.set_xscale('log', base=10)\n",
    "ax1.set_yscale('log', base=10)\n",
    "ax1.legend(fontsize=14)\n",
    "ax1.set_xlabel('Distance in the input space', fontsize = 16)\n",
    "ax1.set_ylabel('Frequency', fontsize = 16)\n",
    "ax1.set_title('(a) Histogram of distance', fontweight=\"bold\")\n",
    "\n",
    "\n",
    "ax2.set_xscale('log', base=10)\n",
    "ax2.set_yscale('log', base=10)\n",
    "ax2.hist(test_mean_sngp,  bins = 20, alpha= 0.5,  label = 'Normal') #color = 'blue',color = 'orange',color = 'green',\n",
    "ax2.hist(shift_mean_sngp, bins = 20, alpha= 0.5, label = 'Shift')\n",
    "ax2.hist(OOD_mean_sngp,   bins = 20, alpha= 0.5,  label = 'OOD')\n",
    "ax2.legend(fontsize=14)\n",
    "ax2.set_xlabel('Distance in the hidden space', fontsize = 16)\n",
    "ax2.set_ylabel('Frequency', fontsize = 16)\n",
    "ax2.set_title('(b) Proposed method', fontweight=\"bold\")\n",
    "\n",
    "ax3.set_xscale('log', base=10)\n",
    "ax3.set_yscale('log', base=10)\n",
    "ax3.hist(test_mean_mc,  bins = 20, alpha= 0.5,  label = 'Normal') #color = 'blue',color = 'orange',color = 'green',\n",
    "ax3.hist(shift_mean_mc, bins = 20, alpha= 0.5, label = 'Shift')\n",
    "ax3.hist(OOD_mean_mc,   bins = 20, alpha= 0.5,  label = 'OOD')\n",
    "ax3.legend(fontsize=14)\n",
    "ax3.set_xlabel('Distance in the hidden space', fontsize = 16)\n",
    "ax3.set_ylabel('Frequency', fontsize = 16)\n",
    "ax3.set_title('(c) MC dropout', fontweight=\"bold\")\n",
    "\n",
    "ax4.set_xscale('log', base=10)\n",
    "ax4.set_yscale('log', base=10)\n",
    "ax4.hist(test_mean_deep,  bins = 20, alpha= 0.5,  label = 'Normal') #color = 'blue',color = 'orange',color = 'green',\n",
    "ax4.hist(shift_mean_deep, bins = 20, alpha= 0.5,  label = 'Shift')\n",
    "ax4.hist(OOD_mean_deep,   bins = 20, alpha= 0.5, label = 'OOD')\n",
    "ax4.legend(fontsize=14)\n",
    "ax4.set_xlabel('Distance in the hidden space', fontsize = 16)\n",
    "ax4.set_ylabel('Frequency', fontsize = 16)\n",
    "ax4.set_title('(d) Deep ensemble', fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Hidden-Distance-comb-reg.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wm4NSZ49HmTU"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'layout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-38127264bc95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"whitegrid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constrained'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_var_sngp\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshift_var_sngp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Shift'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(nrows, ncols, sharex, sharey, squeeze, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[0msubplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \"\"\"\n\u001b[0;32m-> 1184\u001b[0;31m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfig_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m     axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,\n\u001b[1;32m   1186\u001b[0m                        \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplot_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplot_kw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mfigure\u001b[0;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                         \u001b[0mframeon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                                         \u001b[0mFigureClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFigureClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m                                         **kwargs)\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfigLabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[0;34m(cls, num, *args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mfig_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FigureClass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_figure_manager_given_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'layout'"
     ]
    }
   ],
   "source": [
    "sns.set(style=\"whitegrid\", font_scale = 1.5)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4.5), layout='constrained' )\n",
    "\n",
    "ax1.hist(test_var_sngp,  bins = 20, alpha= 0.5,  label = 'Normal') \n",
    "ax1.hist(shift_var_sngp, bins = 20, alpha= 0.5, label = 'Shift')\n",
    "ax1.hist(OOD_var_sngp,   bins = 20, alpha= 0.5,  label = 'OOD')\n",
    "\n",
    "ax1.set_xscale('log', base=10)\n",
    "ax1.set_yscale('log', base=10)\n",
    "ax1.legend(fontsize=14)\n",
    "ax1.set_xlabel('Variance', fontsize = 16)\n",
    "ax1.set_ylabel('Frequency', fontsize = 16)\n",
    "ax1.set_title('(a) Proposed method', fontweight=\"bold\")\n",
    "\n",
    "ax2.hist(test_var_mc,  bins = 20, alpha= 0.5, label = 'Normal') \n",
    "ax2.hist(shift_var_mc, bins = 20, alpha= 0.5,  label = 'Shift')\n",
    "ax2.hist(OOD_var_mc,   bins = 20, alpha= 0.5,  label = 'OOD')\n",
    "ax2.set_xscale('log', base=10)\n",
    "ax2.set_yscale('log', base=10)\n",
    "ax2.legend(fontsize=14)\n",
    "ax2.set_xlabel('Variance', fontsize = 16)\n",
    "ax2.set_ylabel('Frequency', fontsize = 16)\n",
    "ax2.set_title('(b) MC dropout', fontweight=\"bold\")\n",
    "\n",
    "ax3.hist(test_var_deep,  bins = 20, alpha= 0.5,  label = 'Normal') \n",
    "ax3.hist(shift_var_deep, bins = 20, alpha= 0.5,  label = 'Shift')\n",
    "ax3.hist(OOD_var_deep,   bins = 20, alpha= 0.5,  label = 'OOD')\n",
    "ax3.set_xscale('log', base=10)\n",
    "ax3.set_yscale('log', base=10)\n",
    "ax3.legend(fontsize=14)\n",
    "ax3.set_xlabel('Variance', fontsize = 16)\n",
    "ax3.set_ylabel('Frequency', fontsize = 16)\n",
    "ax3.set_title('(c) Deep ensemble', fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('Var-hist-comb-reg.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyTxvOjSChjn"
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", font_scale = 1.5)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4.5), layout='constrained' )\n",
    "\n",
    "ax1.hist(test_var_sngp,  bins = 20, alpha= 0.5, density=True, label = 'Normal') \n",
    "ax1.hist(shift_var_sngp, bins = 20, alpha= 0.5, density=True, label = 'Shift')\n",
    "ax1.hist(OOD_var_sngp,   bins = 20, alpha= 0.5, density=True, label = 'OOD')\n",
    "\n",
    "ax1.set_xscale('log', base=10)\n",
    "ax1.set_yscale('log', base=10)\n",
    "ax1.legend(fontsize=14)\n",
    "ax1.set_xlabel('Variance', fontsize = 16)\n",
    "ax1.set_ylabel('Frequency', fontsize = 16)\n",
    "ax1.set_title('(a) Proposed method', fontweight=\"bold\")\n",
    "\n",
    "ax2.hist(test_var_mc,  bins = 20, alpha= 0.5, density=True, label = 'Normal') \n",
    "ax2.hist(shift_var_mc, bins = 20, alpha= 0.5, density=True, label = 'Shift')\n",
    "ax2.hist(OOD_var_mc,   bins = 20, alpha= 0.5, density=True, label = 'OOD')\n",
    "ax2.set_xscale('log', base=10)\n",
    "ax2.set_yscale('log', base=10)\n",
    "ax2.legend(fontsize=14)\n",
    "ax2.set_xlabel('Variance', fontsize = 16)\n",
    "ax2.set_ylabel('Frequency', fontsize = 16)\n",
    "ax2.set_title('(b) MC dropout', fontweight=\"bold\")\n",
    "\n",
    "ax3.hist(test_var_deep,  bins = 20, alpha= 0.5, density=True, label = 'Normal') \n",
    "ax3.hist(shift_var_deep, bins = 20, alpha= 0.5, density=True, label = 'Shift')\n",
    "ax3.hist(OOD_var_deep,   bins = 20, alpha= 0.5, density=True, label = 'OOD')\n",
    "ax3.set_xscale('log', base=10)\n",
    "ax3.set_yscale('log', base=10)\n",
    "ax3.legend(fontsize=14)\n",
    "ax3.set_xlabel('Variance', fontsize = 16)\n",
    "ax3.set_ylabel('Frequency', fontsize = 16)\n",
    "ax3.set_title('(c) Deep ensemble', fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('Var-hist-comb-reg.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wU2kKLz-KiXU"
   },
   "outputs": [],
   "source": [
    "def cal_correlation(x1, x2):\n",
    "    correlation_matrix = np.corrcoef(x1, x2)\n",
    "    correlation_coefficient = correlation_matrix[0, 1]\n",
    "    return correlation_coefficient\n",
    "\n",
    "def concat_data(x1, x2, x3):\n",
    "    return np.concatenate((x1, x2, x3), axis = 0)\n",
    "\n",
    "sngp_dist = concat_data(test_mean_sngp,shift_mean_sngp,OOD_mean_sngp)\n",
    "sngp_var =  concat_data(test_var_sngp, shift_var_sngp, OOD_var_sngp)\n",
    "print(cal_correlation(sngp_dist, sngp_var))\n",
    "print(cal_correlation(test_mean_sngp,  test_var_sngp))\n",
    "print(cal_correlation(shift_mean_sngp, shift_var_sngp))\n",
    "print(cal_correlation(OOD_mean_sngp,   OOD_var_sngp))\n",
    "\n",
    "\n",
    "mc_dist = concat_data(test_mean_mc, shift_mean_mc, OOD_mean_mc)\n",
    "mc_var =  concat_data(test_var_mc, shift_var_mc, OOD_var_mc.numpy().ravel())\n",
    "print(cal_correlation(mc_dist, mc_var))\n",
    "print(cal_correlation(test_mean_mc,  test_var_mc ))\n",
    "print(cal_correlation(shift_mean_mc, shift_var_mc ))\n",
    "print(cal_correlation(OOD_mean_mc,   OOD_var_mc.numpy().ravel()))\n",
    "\n",
    "\n",
    "\n",
    "deep_dist = concat_data(test_mean_deep, shift_mean_deep, OOD_mean_deep)\n",
    "deep_var =  concat_data(test_var_deep.ravel(), shift_var_deep.ravel(), OOD_var_deep.ravel())\n",
    "print(cal_correlation(deep_dist, deep_var))\n",
    "\n",
    "print(cal_correlation(test_mean_deep,  test_var_deep.ravel()))\n",
    "print(cal_correlation(shift_mean_deep, shift_var_deep.ravel()))\n",
    "print(cal_correlation(OOD_mean_deep,   OOD_var_deep.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007415477\n",
      "0.11560254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_221652/2511608927.py:19: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"whitegrid\", font_scale = 1.5)\n",
    "fig, (ax1) = plt.subplots(1,1, figsize=(10, 6), layout='constrained' )\n",
    "\n",
    "ax1.hist(test_var_sngp,  bins = 20, alpha= 0.5, density=True, label = 'Normal') \n",
    "\n",
    "plt.axvline(x= test_var_sngp.max(), color = 'blue', lw = 2, ls = '--' )\n",
    "print(test_var_sngp.max())\n",
    "ax1.hist(shift_var_sngp, bins = 20, alpha= 0.5, density=True, label = 'Shift')\n",
    "plt.axvline(x= OOD_var_sngp.min(), color = 'red', lw = 2, ls = '--')\n",
    "print(OOD_var_sngp.min())\n",
    "ax1.hist(OOD_var_sngp,   bins = 20, alpha= 0.5, density=True, label = 'OOD')\n",
    "\n",
    "ax1.set_xscale('log', base=10)\n",
    "ax1.set_yscale('log', base=10)\n",
    "ax1.legend(fontsize=14)\n",
    "ax1.set_xlabel('Predictive uncertainty', fontsize = 16)\n",
    "ax1.set_ylabel('Frequency', fontsize = 16)\n",
    "# ax1.set_title('Proposed method', fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('var_risk_reg.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VN9vaEjRKiXV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
